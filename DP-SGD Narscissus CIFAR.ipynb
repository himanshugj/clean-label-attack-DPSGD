{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ef915ce",
   "metadata": {},
   "source": [
    "## Narcissus* Backdoor attack on DP-SGD training \n",
    "- CIFAR 10 dataset\n",
    "- Clean label attack\n",
    "\n",
    "`*` Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, and Ruoxi Jia. 2023. Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security (CCS '23). Association for Computing Machinery, New York, NY, USA, 771–785. https://doi.org/10.1145/3576915.3616617"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cccbb0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8218a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "import torch.backends.cudnn as cudnn\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader,Subset\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2 as cv\n",
    "# from util import *\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from opacus.utils.uniform_sampler import UniformWithReplacementSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9797be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set device\n",
    "torch.cuda.set_device(5)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2226ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#util file for Narcissu Attack.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# import cv2 as cv\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    maxk = max(topk)\n",
    "\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(1/batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.max = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.max = max(self.max, val)\n",
    "\n",
    "\n",
    "def torch_normalization(data):\n",
    "    new_data = data.clone()\n",
    "    if data.dim() == 4:\n",
    "        _range1 = torch.max(data[0,0,:,:]) - torch.min(data[0,0,:,:])\n",
    "        _range2 = torch.max(data[0,1,:,:]) - torch.min(data[0,1,:,:])\n",
    "        _range3 = torch.max(data[0,2,:,:]) - torch.min(data[0,2,:,:])\n",
    "        if _range1 > 0:\n",
    "            new_data[0,0,:,:] = (data[0,0,:,:] - torch.min(data[0,0,:,:])) / _range1\n",
    "        if _range2 > 0:\n",
    "            new_data[0,1,:,:] = (data[0,1,:,:] - torch.min(data[0,1,:,:])) / _range2\n",
    "        if _range3 > 0:\n",
    "            new_data[0,2,:,:] = (data[0,2,:,:] - torch.min(data[0,2,:,:])) / _range3\n",
    "    return new_data\n",
    "\n",
    "def torch_normalization_inv(data,epsilon):\n",
    "    new_data = data.clone()\n",
    "    if data.dim() == 4:\n",
    "        _range1 = torch.max(data[0,0,:,:]) - torch.min(data[0,0,:,:])\n",
    "        _range2 = torch.max(data[0,1,:,:]) - torch.min(data[0,1,:,:])\n",
    "        _range3 = torch.max(data[0,2,:,:]) - torch.min(data[0,2,:,:])\n",
    "        if _range1 > 0:\n",
    "            new_data[0,0,:,:] = (data[0,0,:,:] - torch.min(data[0,0,:,:])) / _range1\n",
    "            new_data[0,0,:,:] = new_data[0,0,:,:]*(epsilon*2)/255\n",
    "            new_data[0,0,:,:] = new_data[0,0,:,:] - epsilon/255\n",
    "        if _range2 > 0:\n",
    "            new_data[0,1,:,:] = (data[0,1,:,:] - torch.min(data[0,1,:,:])) / _range2\n",
    "            new_data[0,1,:,:] = new_data[0,1,:,:]*(epsilon*2)/255\n",
    "            new_data[0,1,:,:] = new_data[0,1,:,:] - epsilon/255\n",
    "        if _range3 > 0:\n",
    "            new_data[0,2,:,:] = (data[0,2,:,:] - torch.min(data[0,2,:,:])) / _range3\n",
    "            new_data[0,2,:,:] = new_data[0,2,:,:]*(epsilon*2)/255\n",
    "            new_data[0,2,:,:] = new_data[0,2,:,:] - epsilon/255\n",
    "    return new_data\n",
    "\n",
    "def norm_weight(weights):\n",
    "    norm = torch.sum(weights)\n",
    "    if norm != 0:\n",
    "        normed_weights = weights / norm\n",
    "    else:\n",
    "        normed_weights = weights\n",
    "    return normed_weights\n",
    "\n",
    "def project_onto_l1_ball(x, eps):\n",
    "    \"\"\"\n",
    "    Compute Euclidean projection onto the L1 ball for a batch.\n",
    "      min ||x - u||_2 s.t. ||u||_1 <= eps\n",
    "    Inspired by the corresponding numpy version by Adrien Gaidon.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: (batch_size, *) torch array\n",
    "      batch of arbitrary-size tensors to project, possibly on GPU\n",
    "    eps: float\n",
    "      radius of l-1 ball to project onto\n",
    "    Returns\n",
    "    -------\n",
    "    u: (batch_size, *) torch array\n",
    "      batch of projected tensors, reshaped to match the original\n",
    "    Notes\n",
    "    -----\n",
    "    The complexity of this algorithm is in O(dlogd) as it involves sorting x.\n",
    "    References\n",
    "    ----------\n",
    "    [1] Efficient Projections onto the l1-Ball for Learning in High Dimensions\n",
    "        John Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra.\n",
    "        International Conference on Machine Learning (ICML 2008)\n",
    "    \"\"\"\n",
    "    original_shape = x.shape\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    mask = (torch.norm(x, p=1, dim=1) < eps).float().unsqueeze(1)\n",
    "    mu, _ = torch.sort(torch.abs(x), dim=1, descending=True)\n",
    "    cumsum = torch.cumsum(mu, dim=1)\n",
    "    arange = torch.arange(1, x.shape[1] + 1, device=x.device)\n",
    "    rho, _ = torch.max((mu * arange > (cumsum - eps)) * arange, dim=1)\n",
    "    theta = (cumsum[torch.arange(x.shape[0]), rho.cpu() - 1] - eps) / rho\n",
    "    proj = (torch.abs(x) - theta.unsqueeze(1)).clamp(min=0)\n",
    "    x = mask * x + (1 - mask) * proj * torch.sign(x)\n",
    "    return x.view(original_shape)\n",
    "\n",
    "def proj_lp(v, xi, p):\n",
    "    # Project on the lp ball centered at 0 and of radius xi\n",
    "    # SUPPORTS only p = 2 and p = Inf for now\n",
    "    if p == 2:\n",
    "        v = v * min(1, xi/torch.linalg.norm(v.flatten(1)))\n",
    "        # v = v / np.linalg.norm(v.flatten(1)) * xi\n",
    "    elif p == 3:\n",
    "        v = torch.sign(v) * torch.minimum(abs(v), torch.tensor(xi))\n",
    "    else:\n",
    "         raise ValueError('Values of p different from 2 and Inf are currently not supported...')\n",
    "    return v\n",
    "\n",
    "def get_dataset_index(target_path,target_label):\n",
    "\n",
    "    all_content=os.listdir(target_path)\n",
    "\n",
    "    lab_count = 0\n",
    "    pass_file = 0\n",
    "    target_len = 0\n",
    "    for content in all_content:\n",
    "        files_name = os.listdir(target_path+content)\n",
    "        if lab_count == target_label:\n",
    "            target_len += len(files_name)\n",
    "            target_list = list(range(pass_file,pass_file+target_len))\n",
    "        pass_file += len(files_name)\n",
    "        lab_count += 1\n",
    "    non_target_list = list(set(list(range(0,pass_file))) - set(target_list))\n",
    "    return target_list,non_target_list\n",
    "\n",
    "class my_subset(Dataset):\n",
    "    r\"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): The whole Dataset\n",
    "        indices (sequence): Indices in the whole set selected for subset\n",
    "        labels(sequence) : targets as required for the indices. will be the same length as indices\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices,labels):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        labels_hold = torch.ones(len(dataset)).type(torch.long) *300 #( some number not present in the #labels just to make sure\n",
    "        labels_hold[self.indices] = labels \n",
    "        self.labels = labels_hold\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[self.indices[idx]][0]\n",
    "        label = self.labels[self.indices[idx]]\n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "        \n",
    "\n",
    "class data_prefetcher():\n",
    "    def __init__(self, loader):\n",
    "        self.loader = iter(loader)\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.mean = torch.tensor([0.485 * 255, 0.456 * 255, 0.406 * 255]).cuda().view(1,3,1,1)\n",
    "        self.std = torch.tensor([0.229 * 255, 0.224 * 255, 0.225 * 255]).cuda().view(1,3,1,1)\n",
    "        self.preload()\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loader)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(non_blocking=True)\n",
    "            self.next_target = self.next_target.cuda(non_blocking=True)\n",
    "            self.next_input = self.next_input.float()\n",
    "            self.next_input = self.next_input.sub_(self.mean).div_(self.std)\n",
    "            \n",
    "    def next(self):\n",
    "        torch.cuda.current_stream().wait_stream(self.stream)\n",
    "        input = self.next_input\n",
    "        target = self.next_target\n",
    "        self.preload()\n",
    "        return input, target\n",
    "    \n",
    "def apply_noise_patch(noise,images,offset_x=0,offset_y=0,mode='change',padding=20,position='fixed'):\n",
    "    '''\n",
    "    noise: torch.Tensor(1, 3, pat_size, pat_size)\n",
    "    images: torch.Tensor(N, 3, 512, 512)\n",
    "    outputs: torch.Tensor(N, 3, 512, 512)\n",
    "    '''\n",
    "    length = images.shape[2] - noise.shape[2]\n",
    "    if position == 'fixed':\n",
    "        wl = offset_x\n",
    "        ht = offset_y\n",
    "    else:\n",
    "        wl = np.random.randint(padding,length-padding)\n",
    "        ht = np.random.randint(padding,length-padding)\n",
    "    if images.dim() == 3:\n",
    "        noise_now = noise.clone()[0,:,:,:]\n",
    "        wr = length-wl\n",
    "        hb = length-ht\n",
    "        m = nn.ZeroPad2d((wl, wr, ht, hb))\n",
    "        if(mode == 'change'):\n",
    "            images[:,ht:ht+noise.shape[2],wl:wl+noise.shape[3]] = 0\n",
    "            images += m(noise_now)\n",
    "        else:\n",
    "            images += noise_now\n",
    "    else:\n",
    "        for i in range(images.shape[0]):\n",
    "            noise_now = noise.clone()\n",
    "            wr = length-wl\n",
    "            hb = length-ht\n",
    "            m = nn.ZeroPad2d((wl, wr, ht, hb))\n",
    "            if(mode == 'change'):\n",
    "                images[i:i+1,:,ht:ht+noise.shape[2],wl:wl+noise.shape[3]] = 0\n",
    "                images[i:i+1] += m(noise_now)\n",
    "            else:\n",
    "                images[i:i+1] += noise_now\n",
    "    return images\n",
    "\n",
    "class poison_label(Dataset):\n",
    "    def __init__(self, dataset,indices,target):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.target = target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[self.indices[idx]][0]\n",
    "        return (image, self.target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "class poison_image(Dataset):\n",
    "    def __init__(self, dataset,indices,noise,transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.noise = noise\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx][0]\n",
    "        if idx in self.indices:\n",
    "            image = torch.clamp(apply_noise_patch(self.noise,image,mode='add'),-1,1)\n",
    "        label = self.dataset[idx][1]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return (image, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "class poison_image_label(Dataset):\n",
    "    def __init__(self, dataset,indices,noise,target,transform):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "        self.noise = noise\n",
    "        self.target = target\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[self.indices[idx]][0]\n",
    "        image = torch.clamp(apply_noise_patch(self.noise,image,mode='add'),-1,1)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return (image, self.target)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "def destructive_append(l,i):\n",
    "    l=l[1:]\n",
    "    l.append(i)\n",
    "    return l\n",
    "\n",
    "class get_labels(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx][1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "def load_pth(input_model,load_file_path):\n",
    "    loaded_dict = torch.load(load_file_path)\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in loaded_dict.items():\n",
    "        name = k[7:]\n",
    "        new_state_dict[name] = v \n",
    "\n",
    "    input_model.load_state_dict(new_state_dict)\n",
    "    input_model = input_model.cuda()\n",
    "    return input_model\n",
    "\n",
    "class concoct_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, target_dataset,outter_dataset):\n",
    "        self.idataset = target_dataset\n",
    "        self.odataset = outter_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.odataset):\n",
    "            img = self.odataset[idx][0]\n",
    "            labels = self.odataset[idx][1]\n",
    "        else:\n",
    "            img = self.idataset[idx-len(self.odataset)][0]\n",
    "            #labels = torch.tensor(len(self.odataset.classes),dtype=torch.long)\n",
    "            labels = len(self.odataset.classes)\n",
    "        #label = self.dataset[idx][1]\n",
    "        return (img,labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idataset)+len(self.odataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b844ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path ='/home/himanshugj/Documents/Project- Gradient Shaping/'\n",
    "\n",
    "#The target class label\n",
    "lab = 2\n",
    "\n",
    "#Noise size, default is full image size\n",
    "noise_size = 32\n",
    "\n",
    "#Radius of the L-inf ball\n",
    "l_inf_r = 16/255\n",
    "\n",
    "#Model for generating surrogate model and trigger\n",
    "surrogate_model = ResNet18_201().cuda()\n",
    "generating_model = ResNet18_201().cuda()\n",
    "\n",
    "#Surrogate model training epochs\n",
    "surrogate_epochs = 200\n",
    "\n",
    "#Learning rate for poison-warm-up\n",
    "generating_lr_warmup = 0.1\n",
    "warmup_round = 5\n",
    "\n",
    "#Learning rate for trigger generating\n",
    "generating_lr_tri = 0.01      \n",
    "gen_round = 1000\n",
    "\n",
    "#Training batch size\n",
    "train_batch_size = 350\n",
    "\n",
    "#The model for adding the noise\n",
    "patch_mode = 'add'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27340d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The argumention use for surrogate model training stage\n",
    "transform_surrogate_train = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "#The argumention use for all training set\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "#The argumention use for all testing set\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47e51c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 21:22:10--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
      "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.68.10\n",
      "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248100043 (237M) [application/zip]\n",
      "Saving to: ‘tiny-imagenet-200.zip.2’\n",
      "\n",
      "tiny-imagenet-200.z 100%[===================>] 236.61M  6.16MB/s    in 52s     \n",
      "\n",
      "2022-12-06 21:23:02 (4.57 MB/s) - ‘tiny-imagenet-200.zip.2’ saved [248100043/248100043]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use a OOD dataset for generating the trigger (public data) for more transferrability\n",
    "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033f556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "total_size = 50000\n",
    "print('==> Preparing data..')\n",
    "from torchvision.datasets import CIFAR10\n",
    "root = '../data/'\n",
    "\n",
    "trainset = CIFAR10(root, train=True, transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
    "# x_train, y_train = trainset.data, trainset.targets\n",
    "# x_train = x_train.astype('float32')/255\n",
    "# y_train = np.asarray(y_train)\n",
    "\n",
    "\n",
    "testset = CIFAR10(root, train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
    "# x_test, y_test = testset.data, testset.targets\n",
    "# x_test = x_test.astype('float32')/255\n",
    "# y_test = np.asarray(y_test)\n",
    "outter_trainset = torchvision.datasets.ImageFolder(root=dataset_path + 'tiny-imagenet-200/train/', transform=transform_surrogate_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f900a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outter train dataset\n",
    "train_label = [get_labels(trainset)[x] for x in range(len(get_labels(trainset)))]\n",
    "test_label = [get_labels(testset)[x] for x in range(len(get_labels(testset)))]\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "#Inner train dataset\n",
    "train_target_list = list(np.where(np.array(train_label)==lab)[0])\n",
    "train_target = Subset(trainset,train_target_list)\n",
    "concoct_train_dataset = concoct_dataset(train_target,outter_trainset)\n",
    "\n",
    "\n",
    "surrogate_loader = torch.utils.data.DataLoader(concoct_train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "poi_warm_up_loader = torch.utils.data.DataLoader(train_target, batch_size=train_batch_size, shuffle=True, num_workers=16)\n",
    "\n",
    "trigger_gen_loaders = torch.utils.data.DataLoader(train_target, batch_size=train_batch_size, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0abe15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training surrogate model\n",
    "\n",
    "\n",
    "# Batch_grad\n",
    "condition = True\n",
    "noise = torch.zeros((1, 3, noise_size, noise_size), device=device)\n",
    "\n",
    "\n",
    "surrogate_model = surrogate_model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# outer_opt = torch.optim.RAdam(params=base_model.parameters(), lr=generating_lr_outer)\n",
    "surrogate_opt = torch.optim.SGD(params=surrogate_model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "surrogate_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(surrogate_opt, T_max=surrogate_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the surrogate model\n",
      "Epoch:0, Loss: 4.525\n",
      "Epoch:1, Loss: 3.834\n",
      "Epoch:2, Loss: 3.366\n",
      "Epoch:3, Loss: 3.057\n",
      "Epoch:4, Loss: 2.822\n",
      "Epoch:5, Loss: 2.634\n",
      "Epoch:6, Loss: 2.486\n",
      "Epoch:7, Loss: 2.372\n",
      "Epoch:8, Loss: 2.273\n",
      "Epoch:9, Loss: 2.200\n",
      "Epoch:10, Loss: 2.124\n",
      "Epoch:11, Loss: 2.067\n",
      "Epoch:12, Loss: 2.021\n",
      "Epoch:13, Loss: 1.960\n",
      "Epoch:14, Loss: 1.920\n",
      "Epoch:15, Loss: 1.880\n",
      "Epoch:16, Loss: 1.831\n",
      "Epoch:17, Loss: 1.800\n",
      "Epoch:18, Loss: 1.773\n",
      "Epoch:19, Loss: 1.738\n",
      "Epoch:20, Loss: 1.716\n",
      "Epoch:21, Loss: 1.684\n",
      "Epoch:22, Loss: 1.656\n",
      "Epoch:23, Loss: 1.634\n",
      "Epoch:24, Loss: 1.613\n",
      "Epoch:25, Loss: 1.583\n",
      "Epoch:26, Loss: 1.572\n",
      "Epoch:27, Loss: 1.553\n",
      "Epoch:28, Loss: 1.536\n",
      "Epoch:29, Loss: 1.521\n",
      "Epoch:30, Loss: 1.496\n",
      "Epoch:31, Loss: 1.485\n",
      "Epoch:32, Loss: 1.471\n",
      "Epoch:33, Loss: 1.451\n",
      "Epoch:34, Loss: 1.438\n",
      "Epoch:38, Loss: 1.389\n",
      "Epoch:39, Loss: 1.371\n",
      "Epoch:42, Loss: 1.331\n",
      "Epoch:43, Loss: 1.319\n",
      "Epoch:44, Loss: 1.311\n",
      "Epoch:45, Loss: 1.291\n",
      "Epoch:46, Loss: 1.284\n",
      "Epoch:47, Loss: 1.278\n",
      "Epoch:48, Loss: 1.260\n",
      "Epoch:49, Loss: 1.247\n",
      "Epoch:50, Loss: 1.236\n",
      "Epoch:51, Loss: 1.229\n",
      "Epoch:52, Loss: 1.213\n",
      "Epoch:53, Loss: 1.202\n",
      "Epoch:54, Loss: 1.189\n",
      "Epoch:55, Loss: 1.181\n",
      "Epoch:56, Loss: 1.177\n",
      "Epoch:57, Loss: 1.152\n",
      "Epoch:58, Loss: 1.141\n",
      "Epoch:59, Loss: 1.136\n",
      "Epoch:60, Loss: 1.122\n",
      "Epoch:61, Loss: 1.102\n",
      "Epoch:62, Loss: 1.096\n",
      "Epoch:63, Loss: 1.082\n",
      "Epoch:64, Loss: 1.081\n",
      "Epoch:65, Loss: 1.049\n",
      "Epoch:66, Loss: 1.048\n",
      "Epoch:67, Loss: 1.028\n",
      "Epoch:68, Loss: 1.027\n",
      "Epoch:69, Loss: 1.014\n",
      "Epoch:70, Loss: 1.003\n",
      "Epoch:71, Loss: 0.983\n",
      "Epoch:72, Loss: 0.975\n",
      "Epoch:73, Loss: 0.961\n",
      "Epoch:74, Loss: 0.950\n",
      "Epoch:75, Loss: 0.940\n",
      "Epoch:76, Loss: 0.924\n",
      "Epoch:77, Loss: 0.917\n",
      "Epoch:78, Loss: 0.902\n",
      "Epoch:79, Loss: 0.877\n",
      "Epoch:80, Loss: 0.879\n",
      "Epoch:81, Loss: 0.865\n",
      "Epoch:82, Loss: 0.846\n",
      "Epoch:83, Loss: 0.838\n",
      "Epoch:84, Loss: 0.814\n",
      "Epoch:85, Loss: 0.808\n",
      "Epoch:86, Loss: 0.794\n",
      "Epoch:87, Loss: 0.778\n",
      "Epoch:88, Loss: 0.765\n",
      "Epoch:89, Loss: 0.748\n",
      "Epoch:90, Loss: 0.735\n",
      "Epoch:91, Loss: 0.732\n",
      "Epoch:92, Loss: 0.716\n",
      "Epoch:93, Loss: 0.686\n",
      "Epoch:94, Loss: 0.682\n",
      "Epoch:95, Loss: 0.666\n",
      "Epoch:96, Loss: 0.651\n",
      "Epoch:97, Loss: 0.642\n",
      "Epoch:98, Loss: 0.618\n",
      "Epoch:99, Loss: 0.612\n",
      "Epoch:100, Loss: 0.596\n",
      "Epoch:101, Loss: 0.578\n",
      "Epoch:102, Loss: 0.569\n",
      "Epoch:103, Loss: 0.549\n",
      "Epoch:104, Loss: 0.538\n",
      "Epoch:105, Loss: 0.541\n",
      "Epoch:106, Loss: 0.502\n",
      "Epoch:107, Loss: 0.501\n",
      "Epoch:108, Loss: 0.492\n",
      "Epoch:109, Loss: 0.470\n",
      "Epoch:110, Loss: 0.456\n",
      "Epoch:111, Loss: 0.446\n",
      "Epoch:112, Loss: 0.422\n",
      "Epoch:113, Loss: 0.420\n",
      "Epoch:114, Loss: 0.405\n",
      "Epoch:115, Loss: 0.388\n",
      "Epoch:116, Loss: 0.380\n",
      "Epoch:117, Loss: 0.365\n",
      "Epoch:120, Loss: 0.325\n",
      "Epoch:121, Loss: 0.318\n",
      "Epoch:122, Loss: 0.304\n",
      "Epoch:123, Loss: 0.290\n",
      "Epoch:124, Loss: 0.272\n",
      "Epoch:125, Loss: 0.268\n",
      "Epoch:126, Loss: 0.255\n",
      "Epoch:127, Loss: 0.233\n",
      "Epoch:128, Loss: 0.218\n",
      "Epoch:129, Loss: 0.216\n",
      "Epoch:130, Loss: 0.199\n",
      "Epoch:131, Loss: 0.186\n",
      "Epoch:132, Loss: 0.178\n",
      "Epoch:133, Loss: 0.168\n",
      "Epoch:134, Loss: 0.159\n",
      "Epoch:135, Loss: 0.147\n",
      "Epoch:136, Loss: 0.134\n",
      "Epoch:137, Loss: 0.122\n",
      "Epoch:138, Loss: 0.111\n",
      "Epoch:139, Loss: 0.096\n",
      "Epoch:140, Loss: 0.091\n",
      "Epoch:141, Loss: 0.081\n",
      "Epoch:142, Loss: 0.069\n",
      "Epoch:143, Loss: 0.058\n",
      "Epoch:144, Loss: 0.052\n",
      "Epoch:145, Loss: 0.042\n",
      "Epoch:146, Loss: 0.040\n",
      "Epoch:147, Loss: 0.032\n",
      "Epoch:148, Loss: 0.029\n",
      "Epoch:149, Loss: 0.027\n",
      "Epoch:150, Loss: 0.025\n",
      "Epoch:151, Loss: 0.024\n",
      "Epoch:152, Loss: 0.024\n",
      "Epoch:153, Loss: 0.022\n",
      "Epoch:154, Loss: 0.022\n",
      "Epoch:155, Loss: 0.021\n",
      "Epoch:156, Loss: 0.021\n",
      "Epoch:157, Loss: 0.021\n",
      "Epoch:158, Loss: 0.020\n",
      "Epoch:159, Loss: 0.020\n",
      "Epoch:160, Loss: 0.019\n",
      "Epoch:161, Loss: 0.019\n",
      "Epoch:162, Loss: 0.019\n",
      "Epoch:163, Loss: 0.019\n",
      "Epoch:164, Loss: 0.019\n",
      "Epoch:165, Loss: 0.018\n",
      "Epoch:166, Loss: 0.018\n",
      "Epoch:167, Loss: 0.017\n",
      "Epoch:168, Loss: 0.018\n",
      "Epoch:169, Loss: 0.017\n",
      "Epoch:170, Loss: 0.017\n",
      "Epoch:171, Loss: 0.017\n",
      "Epoch:172, Loss: 0.017\n",
      "Epoch:173, Loss: 0.016\n",
      "Epoch:174, Loss: 0.016\n",
      "Epoch:175, Loss: 0.016\n",
      "Epoch:176, Loss: 0.016\n",
      "Epoch:177, Loss: 0.016\n",
      "Epoch:178, Loss: 0.016\n",
      "Epoch:179, Loss: 0.016\n",
      "Epoch:180, Loss: 0.015\n",
      "Epoch:181, Loss: 0.015\n",
      "Epoch:182, Loss: 0.015\n",
      "Epoch:183, Loss: 0.015\n",
      "Epoch:184, Loss: 0.015\n",
      "Epoch:185, Loss: 0.015\n",
      "Epoch:186, Loss: 0.015\n",
      "Epoch:187, Loss: 0.015\n",
      "Epoch:188, Loss: 0.015\n",
      "Epoch:189, Loss: 0.014\n",
      "Epoch:190, Loss: 0.014\n",
      "Epoch:191, Loss: 0.014\n",
      "Epoch:192, Loss: 0.014\n",
      "Epoch:193, Loss: 0.014\n",
      "Epoch:194, Loss: 0.014\n",
      "Epoch:195, Loss: 0.014\n",
      "Epoch:196, Loss: 0.014\n",
      "Epoch:197, Loss: 0.014\n",
      "Epoch:198, Loss: 0.014\n"
     ]
    }
   ],
   "source": [
    "#Training the surrogate model\n",
    "print('Training the surrogate model')\n",
    "for epoch in range(0, surrogate_epochs):\n",
    "    surrogate_model.train()\n",
    "    loss_list = []\n",
    "    for images, labels in surrogate_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        surrogate_opt.zero_grad()\n",
    "        outputs = surrogate_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        loss_list.append(float(loss.data))\n",
    "        surrogate_opt.step()\n",
    "    surrogate_scheduler.step()\n",
    "    ave_loss = np.average(np.array(loss_list))\n",
    "    print('Epoch:%d, Loss: %.03f' % (epoch, ave_loss))\n",
    "#Save the surrogate model\n",
    "# save_path = './checkpoint/surrogate_pretrain_' + str(surrogate_epochs) +'.pth'\n",
    "# torch.save(surrogate_model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b3d09",
   "metadata": {},
   "source": [
    "## Poisoning Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poison Warmup over target class\n",
    "#Prepare models and optimizers for poi_warm_up training\n",
    "poi_warm_up_model = generating_model\n",
    "poi_warm_up_model.load_state_dict(surrogate_model.state_dict())\n",
    "\n",
    "poi_warm_up_opt = torch.optim.RAdam(params=poi_warm_up_model.parameters(), lr=generating_lr_warmup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414c130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6558dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poi_warm_up stage\n",
    "poi_warm_up_model.train()\n",
    "for param in poi_warm_up_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "#Training the surrogate model\n",
    "for epoch in range(0, warmup_round):\n",
    "    poi_warm_up_model.train()\n",
    "    loss_list = []\n",
    "    for images, labels in poi_warm_up_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        poi_warm_up_model.zero_grad()\n",
    "        poi_warm_up_opt.zero_grad()\n",
    "        outputs = poi_warm_up_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward(retain_graph = True)\n",
    "        loss_list.append(float(loss.data))\n",
    "        poi_warm_up_opt.step()\n",
    "    ave_loss = np.average(np.array(loss_list))\n",
    "    print('Epoch:%d, Loss: %e' % (epoch, ave_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1691395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: 1.2963619e-05 Loss: 3.483402323922746e-07\n",
      "Gradient: 7.279827e-05 Loss: 3.3037938938681086e-07\n",
      "Gradient: 1.4795714e-05 Loss: 3.2268203398189144e-07\n",
      "Gradient: 4.5925844e-06 Loss: 2.989196085915561e-07\n",
      "Gradient: 1.6461094e-05 Loss: 2.856250304716923e-07\n",
      "Gradient: 2.530908e-05 Loss: 3.1055680646356144e-07\n",
      "Gradient: 2.6730759e-05 Loss: 2.743399074726464e-07\n",
      "Gradient: 1.1459284e-05 Loss: 2.9847687083398947e-07\n",
      "Gradient: 1.5629e-05 Loss: 2.8466000211816815e-07\n",
      "Gradient: 3.803774e-05 Loss: 2.987946421247519e-07\n",
      "Gradient: 1.2279869e-05 Loss: 2.6030723555929094e-07\n",
      "Gradient: 3.2464095e-06 Loss: 2.657113602329749e-07\n",
      "Gradient: 1.5950438e-05 Loss: 2.7288671849608667e-07\n",
      "Gradient: 6.752604e-06 Loss: 2.6591563321668826e-07\n",
      "Gradient: 1.3158186e-05 Loss: 2.412678512087041e-07\n",
      "Gradient: 1.7486816e-05 Loss: 3.08138447261778e-07\n",
      "Gradient: 4.1805906e-06 Loss: 2.5061158244928566e-07\n",
      "Gradient: 1.1548353e-05 Loss: 2.6018237827922043e-07\n",
      "Gradient: 7.4184327e-06 Loss: 2.2957405766040513e-07\n",
      "Gradient: 7.034181e-06 Loss: 2.4966925309399813e-07\n",
      "Gradient: 2.1921473e-06 Loss: 2.3883828295841646e-07\n",
      "Gradient: 7.3990896e-06 Loss: 2.7901738898587305e-07\n",
      "Gradient: 2.1817883e-05 Loss: 2.831725945876921e-07\n",
      "Gradient: 1.74873e-05 Loss: 2.532568965799934e-07\n",
      "Gradient: 2.0978573e-06 Loss: 2.2614542037520852e-07\n",
      "Gradient: 1.7156413e-05 Loss: 2.525756987855251e-07\n",
      "Gradient: 2.63972e-05 Loss: 2.74123910533793e-07\n",
      "Gradient: 5.2540504e-06 Loss: 2.2237608826950842e-07\n",
      "Gradient: 5.0960476e-05 Loss: 2.520987536058783e-07\n",
      "Gradient: 1.594576e-05 Loss: 2.3084556725431563e-07\n",
      "Gradient: 3.4141488e-06 Loss: 2.1493970336905477e-07\n",
      "Gradient: 5.9218346e-06 Loss: 2.197875365557896e-07\n",
      "Gradient: 1.7346592e-05 Loss: 2.4345887510435206e-07\n",
      "Gradient: 7.712104e-06 Loss: 2.2854081104621098e-07\n",
      "Gradient: 1.8175298e-05 Loss: 2.0784392660289086e-07\n",
      "Gradient: 1.0647211e-05 Loss: 2.471033724305016e-07\n",
      "Gradient: 7.8937455e-06 Loss: 2.1177213795908756e-07\n",
      "Gradient: 1.4420814e-05 Loss: 2.1937877197804786e-07\n",
      "Gradient: 1.4774947e-05 Loss: 2.354096181989007e-07\n",
      "Gradient: 4.51784e-06 Loss: 2.2167213558077493e-07\n",
      "Gradient: 2.519985e-05 Loss: 2.2469200568290642e-07\n",
      "Gradient: 2.521417e-05 Loss: 2.2158133721935277e-07\n",
      "Gradient: 6.2337517e-06 Loss: 2.4206245399227553e-07\n",
      "Gradient: 4.125527e-06 Loss: 2.1431511380380167e-07\n",
      "Gradient: 5.230618e-06 Loss: 2.2783700993992778e-07\n",
      "Gradient: 7.550948e-07 Loss: 2.2226255443532258e-07\n",
      "Gradient: 7.901785e-06 Loss: 1.883276283365376e-07\n",
      "Gradient: 1.9254256e-05 Loss: 2.477619451231779e-07\n",
      "Gradient: 1.494698e-05 Loss: 2.2105919062672303e-07\n",
      "Gradient: 8.818512e-06 Loss: 2.0417677812171557e-07\n",
      "Gradient: 2.0079293e-05 Loss: 2.377028820887972e-07\n",
      "Gradient: 6.7880496e-06 Loss: 2.0852513718712847e-07\n",
      "Gradient: 7.752324e-06 Loss: 2.3756679752295894e-07\n",
      "Gradient: 9.736705e-06 Loss: 2.3444463082000766e-07\n",
      "Gradient: 4.2154375e-06 Loss: 2.0900191704716539e-07\n",
      "Gradient: 4.8586044e-06 Loss: 2.2004866077433385e-07\n",
      "Gradient: 2.3968756e-05 Loss: 2.1036417242233558e-07\n",
      "Gradient: 2.9763678e-06 Loss: 2.148032817691122e-07\n",
      "Gradient: 1.7482234e-05 Loss: 2.061976677699325e-07\n",
      "Gradient: 6.420724e-06 Loss: 2.0255329928886568e-07\n",
      "Gradient: 1.6636503e-05 Loss: 2.152348429262929e-07\n",
      "Gradient: 3.53e-06 Loss: 1.9092760889331354e-07\n",
      "Gradient: 7.0750957e-06 Loss: 2.013952342376039e-07\n",
      "Gradient: 5.867115e-06 Loss: 2.249873735612103e-07\n",
      "Gradient: 2.8793846e-05 Loss: 2.1012587367863488e-07\n",
      "Gradient: 9.0900687e-07 Loss: 2.1876571783726226e-07\n",
      "Gradient: 5.173594e-06 Loss: 1.7967653273368948e-07\n",
      "Gradient: 6.9205876e-06 Loss: 2.0089565803497558e-07\n",
      "Gradient: 1.023937e-05 Loss: 1.9191530024424233e-07\n",
      "Gradient: 2.4873202e-06 Loss: 1.9718320534896823e-07\n",
      "Gradient: 1.3944183e-05 Loss: 2.4199410688652277e-07\n",
      "Gradient: 2.6150046e-05 Loss: 2.2208089850058362e-07\n",
      "Gradient: 6.024475e-06 Loss: 1.9678583716616533e-07\n",
      "Gradient: 3.4482996e-06 Loss: 1.9935169225012334e-07\n",
      "Gradient: 6.6857965e-06 Loss: 2.1468988459597919e-07\n",
      "Gradient: 1.3701994e-05 Loss: 2.2174030149813008e-07\n",
      "Gradient: 6.147344e-06 Loss: 1.969221206839696e-07\n",
      "Gradient: 7.948493e-06 Loss: 2.0142931210405852e-07\n",
      "Gradient: 1.1973489e-05 Loss: 2.1673345287354096e-07\n",
      "Gradient: 1.1759159e-05 Loss: 1.99090551215401e-07\n",
      "Gradient: 2.0368886e-06 Loss: 1.991472432886591e-07\n",
      "Gradient: 6.309654e-06 Loss: 1.9913597502826025e-07\n",
      "Gradient: 3.6753804e-06 Loss: 1.9348202187075004e-07\n",
      "Gradient: 1.0406409e-05 Loss: 2.096491310036678e-07\n",
      "Gradient: 1.1901509e-05 Loss: 1.9058681625476007e-07\n",
      "Gradient: 8.989924e-06 Loss: 2.2177424862472133e-07\n",
      "Gradient: 4.1197045e-06 Loss: 1.8563695505235956e-07\n",
      "Gradient: 1.0223484e-05 Loss: 2.684134130959137e-07\n",
      "Gradient: 3.9054717e-06 Loss: 1.8371823765998366e-07\n",
      "Gradient: 1.1021868e-06 Loss: 1.981254120172101e-07\n",
      "Gradient: 9.041782e-06 Loss: 2.2028717173346497e-07\n",
      "Gradient: 2.2960116e-06 Loss: 1.9239205215626498e-07\n",
      "Gradient: 1.6852133e-06 Loss: 1.7779189202353032e-07\n",
      "Gradient: 9.152145e-06 Loss: 1.9739894412396098e-07\n",
      "Gradient: 5.5295563e-06 Loss: 1.7220595391146769e-07\n",
      "Gradient: 6.2562253e-06 Loss: 2.0341602512038055e-07\n",
      "Gradient: 7.661737e-06 Loss: 1.948898666152369e-07\n",
      "Gradient: 1.2454043e-05 Loss: 2.018607242841123e-07\n",
      "Gradient: 2.1236478e-06 Loss: 2.0369996605040798e-07\n",
      "Gradient: 2.8703362e-06 Loss: 1.915066119314209e-07\n",
      "Gradient: 1.9986446e-06 Loss: 1.622038302192171e-07\n",
      "Gradient: 2.2013396e-06 Loss: 1.858867364035177e-07\n",
      "Gradient: 4.457365e-06 Loss: 2.1772101585308216e-07\n",
      "Gradient: 7.1414515e-06 Loss: 1.872832138853179e-07\n",
      "Gradient: 7.653448e-07 Loss: 1.4570755867045666e-07\n",
      "Gradient: 6.8406634e-06 Loss: 1.7820055925691728e-07\n",
      "Gradient: 6.732214e-06 Loss: 1.9922678783738472e-07\n",
      "Gradient: 1.6445181e-05 Loss: 1.8182222921344268e-07\n",
      "Gradient: 3.024541e-06 Loss: 1.9571863300408646e-07\n",
      "Gradient: 1.6849848e-06 Loss: 1.8548922279630156e-07\n",
      "Gradient: 4.1838266e-06 Loss: 2.0955832932637956e-07\n",
      "Gradient: 5.9161157e-06 Loss: 2.0785521428479115e-07\n",
      "Gradient: 1.3055567e-06 Loss: 1.865678730913108e-07\n",
      "Gradient: 5.6395797e-06 Loss: 1.699808422017668e-07\n",
      "Gradient: 6.750684e-06 Loss: 1.9046202908157285e-07\n",
      "Gradient: 5.146464e-06 Loss: 1.861252014142186e-07\n",
      "Gradient: 6.9791045e-06 Loss: 1.860796276768421e-07\n",
      "Gradient: 1.0972244e-05 Loss: 1.967291069604471e-07\n",
      "Gradient: 8.793096e-07 Loss: 1.9151789132365593e-07\n",
      "Gradient: 8.812223e-07 Loss: 1.8000565920791208e-07\n",
      "Gradient: 1.9692582e-06 Loss: 1.9842069084082445e-07\n",
      "Gradient: 9.55342e-06 Loss: 1.9082530210804787e-07\n",
      "Gradient: 7.4610884e-06 Loss: 1.8307106609919781e-07\n",
      "Gradient: 6.6181115e-06 Loss: 2.2788238567272857e-07\n",
      "Gradient: 7.692282e-06 Loss: 1.9846618618165242e-07\n",
      "Gradient: 6.418324e-06 Loss: 1.7924508171063281e-07\n",
      "Gradient: 1.7992537e-06 Loss: 1.7729241079678105e-07\n",
      "Gradient: 9.160813e-06 Loss: 1.9269867929475973e-07\n",
      "Gradient: 7.6173187e-06 Loss: 1.8061886279951979e-07\n",
      "Gradient: 5.3545614e-06 Loss: 2.3160621296369754e-07\n",
      "Gradient: 1.1118234e-05 Loss: 1.9265323961311272e-07\n",
      "Gradient: 2.8893505e-06 Loss: 1.9434495091748734e-07\n",
      "Gradient: 3.288087e-06 Loss: 1.8803251743785647e-07\n",
      "Gradient: 2.7978997e-06 Loss: 1.7671335162579755e-07\n",
      "Gradient: 1.9177487e-06 Loss: 1.7318244237192932e-07\n",
      "Gradient: 2.3818634e-06 Loss: 1.8070966092409436e-07\n",
      "Gradient: 9.188891e-07 Loss: 1.7227419609374314e-07\n",
      "Gradient: 1.0201774e-06 Loss: 1.7334145757293603e-07\n",
      "Gradient: 6.569232e-07 Loss: 1.9123404075097975e-07\n",
      "Gradient: 4.2912234e-06 Loss: 1.984888200468049e-07\n",
      "Gradient: 2.8991776e-06 Loss: 1.8102753216453493e-07\n",
      "Gradient: 2.2572053e-06 Loss: 1.928007774173087e-07\n",
      "Gradient: 3.850187e-06 Loss: 1.944471174889865e-07\n",
      "Gradient: 2.2301674e-06 Loss: 1.585254385834863e-07\n",
      "Gradient: 1.099606e-05 Loss: 2.0973969583337748e-07\n",
      "Gradient: 1.9908543e-06 Loss: 1.7726951237288328e-07\n",
      "Gradient: 1.8998086e-06 Loss: 2.020537337443784e-07\n",
      "Gradient: 7.8687535e-06 Loss: 1.9449252590675315e-07\n",
      "Gradient: 7.3597107e-07 Loss: 1.758391081333836e-07\n",
      "Gradient: 1.1832639e-06 Loss: 1.820267215180138e-07\n",
      "Gradient: 5.558717e-07 Loss: 1.7040094585733337e-07\n",
      "Gradient: 1.3070128e-06 Loss: 2.0261007236399564e-07\n",
      "Gradient: 3.7645846e-06 Loss: 1.877598781637365e-07\n",
      "Gradient: 3.4638883e-06 Loss: 2.0041890470186747e-07\n",
      "Gradient: 2.8473946e-06 Loss: 1.8019875606493466e-07\n",
      "Gradient: 2.5069132e-06 Loss: 1.8103892784893105e-07\n",
      "Gradient: 2.9047028e-06 Loss: 1.7874557632543048e-07\n",
      "Gradient: 1.9628912e-06 Loss: 1.9100694667410305e-07\n",
      "Gradient: 3.0150668e-06 Loss: 2.0313235751245884e-07\n",
      "Gradient: 9.2877326e-07 Loss: 1.859547835418122e-07\n",
      "Gradient: 5.7724737e-06 Loss: 1.9870456616407258e-07\n",
      "Gradient: 2.2561312e-06 Loss: 1.992609161523736e-07\n",
      "Gradient: 5.6253125e-06 Loss: 2.5176967284323836e-07\n",
      "Gradient: 1.3448957e-06 Loss: 1.4913632805739023e-07\n",
      "Gradient: 2.5516397e-06 Loss: 1.7999443050105886e-07\n",
      "Gradient: 3.3095375e-06 Loss: 1.7549851989429043e-07\n",
      "Gradient: 1.8550215e-06 Loss: 1.684027746288545e-07\n",
      "Gradient: 6.8714576e-07 Loss: 2.1839085609561456e-07\n",
      "Gradient: 4.137605e-06 Loss: 1.744198861786117e-07\n",
      "Gradient: 6.1549554e-06 Loss: 1.574582412899872e-07\n",
      "Gradient: 3.0688707e-06 Loss: 1.7558934501948896e-07\n",
      "Gradient: 8.038215e-06 Loss: 1.9657002946852724e-07\n",
      "Gradient: 6.827388e-07 Loss: 1.6548491856838155e-07\n",
      "Gradient: 2.520459e-06 Loss: 1.9334589206702428e-07\n",
      "Gradient: 5.1899433e-06 Loss: 1.9097299220523685e-07\n",
      "Gradient: 1.0931913e-06 Loss: 1.7825736335908006e-07\n",
      "Gradient: 2.4289197e-06 Loss: 1.7689494266429999e-07\n",
      "Gradient: 5.066314e-06 Loss: 1.9881811634074134e-07\n",
      "Gradient: 4.8339843e-06 Loss: 1.9391358658064443e-07\n",
      "Gradient: 2.1558888e-06 Loss: 1.7612294698210462e-07\n",
      "Gradient: 1.4962671e-06 Loss: 2.0925159892234053e-07\n",
      "Gradient: 3.912492e-06 Loss: 1.5819616739539317e-07\n",
      "Gradient: 1.4689691e-06 Loss: 1.589455341862352e-07\n",
      "Gradient: 2.5332008e-06 Loss: 1.807210892934563e-07\n",
      "Gradient: 1.4002596e-06 Loss: 1.9692204157687836e-07\n",
      "Gradient: 4.3583414e-06 Loss: 2.032912680268358e-07\n",
      "Gradient: 4.949357e-06 Loss: 1.7736040689442233e-07\n",
      "Gradient: 2.9107111e-06 Loss: 1.677329407812067e-07\n",
      "Gradient: 3.1875904e-06 Loss: 1.4417495582582282e-07\n",
      "Gradient: 2.5306567e-06 Loss: 1.9462873268594194e-07\n",
      "Gradient: 1.6352624e-06 Loss: 1.743746153692882e-07\n",
      "Gradient: 6.310431e-07 Loss: 1.758845236565776e-07\n",
      "Gradient: 1.2162825e-06 Loss: 1.873171828018864e-07\n",
      "Gradient: 4.37169e-06 Loss: 1.8317322035462286e-07\n",
      "Gradient: 1.0330657e-06 Loss: 1.7188814093553144e-07\n",
      "Gradient: 9.804756e-07 Loss: 1.6130699549421478e-07\n",
      "Gradient: 4.493795e-06 Loss: 1.7577105353439039e-07\n",
      "Gradient: 5.5167135e-07 Loss: 1.6866385668852975e-07\n",
      "Gradient: 9.938856e-07 Loss: 1.7346638069663338e-07\n",
      "Gradient: 1.6811287e-06 Loss: 1.58116717585699e-07\n",
      "Gradient: 2.7431283e-06 Loss: 1.6348679281463775e-07\n",
      "Gradient: 2.9980317e-06 Loss: 1.9503739044542574e-07\n",
      "Gradient: 7.142022e-06 Loss: 1.7839360021791133e-07\n",
      "Gradient: 2.386723e-06 Loss: 1.5384794712266134e-07\n",
      "Gradient: 1.2703365e-06 Loss: 1.7017381045055421e-07\n",
      "Gradient: 4.6549712e-06 Loss: 2.0163365164194146e-07\n",
      "Gradient: 7.2806466e-07 Loss: 1.7087779392947294e-07\n",
      "Gradient: 1.7926905e-06 Loss: 1.7075284404199919e-07\n",
      "Gradient: 7.3636083e-06 Loss: 2.2567995093443944e-07\n",
      "Gradient: 1.1120516e-06 Loss: 1.6446316521978588e-07\n",
      "Gradient: 2.1054293e-06 Loss: 1.7847311942394602e-07\n",
      "Gradient: 1.1015504e-06 Loss: 1.9297120653997505e-07\n",
      "Gradient: 4.5587803e-06 Loss: 1.8005115265395943e-07\n",
      "Gradient: 9.684174e-06 Loss: 1.8882708895754756e-07\n",
      "Gradient: 1.3056773e-06 Loss: 1.787796068223694e-07\n",
      "Gradient: 6.8955444e-07 Loss: 1.827646507024383e-07\n",
      "Gradient: 3.697445e-06 Loss: 1.7120698648416994e-07\n",
      "Gradient: 1.6746299e-06 Loss: 1.7007163251037126e-07\n",
      "Gradient: 3.4952154e-06 Loss: 1.840133904806862e-07\n",
      "Gradient: 3.1835662e-06 Loss: 1.7275105742934708e-07\n",
      "Gradient: 8.335346e-06 Loss: 2.099328033485411e-07\n",
      "Gradient: 9.068488e-06 Loss: 2.525416268402599e-07\n",
      "Gradient: 3.1730774e-06 Loss: 1.73454830587616e-07\n",
      "Gradient: 2.5838025e-07 Loss: 1.5620931629693283e-07\n",
      "Gradient: 2.8882707e-06 Loss: 1.8883862225038682e-07\n",
      "Gradient: 5.874768e-06 Loss: 1.9398160257348234e-07\n",
      "Gradient: 3.7124667e-06 Loss: 1.7036687557000127e-07\n",
      "Gradient: 3.0802757e-06 Loss: 1.655870706921784e-07\n",
      "Gradient: 1.6149243e-06 Loss: 1.9553696025316944e-07\n",
      "Gradient: 2.3481302e-06 Loss: 1.732278548161048e-07\n",
      "Gradient: 4.561163e-06 Loss: 1.9184719567041004e-07\n",
      "Gradient: 7.9482516e-07 Loss: 1.6022843946454183e-07\n",
      "Gradient: 3.1668878e-06 Loss: 1.545972603859506e-07\n",
      "Gradient: 1.2970102e-06 Loss: 1.560163868911483e-07\n",
      "Gradient: 4.9221335e-06 Loss: 1.9477634959722916e-07\n",
      "Gradient: 1.0797456e-06 Loss: 1.5498322506838727e-07\n",
      "Gradient: 3.855622e-06 Loss: 1.9672905674876043e-07\n",
      "Gradient: 6.8422355e-07 Loss: 2.1247585676083722e-07\n",
      "Gradient: 1.6469725e-06 Loss: 1.8450171287061798e-07\n",
      "Gradient: 7.27266e-07 Loss: 2.0371131862854477e-07\n",
      "Gradient: 4.185937e-06 Loss: 1.974670515399642e-07\n",
      "Gradient: 2.5751126e-06 Loss: 1.8796433186215228e-07\n",
      "Gradient: 7.294009e-06 Loss: 1.8656791382909433e-07\n",
      "Gradient: 1.372949e-06 Loss: 1.9793256361329744e-07\n",
      "Gradient: 1.4078536e-06 Loss: 1.8760099228150768e-07\n",
      "Gradient: 3.9876495e-06 Loss: 1.973080718660943e-07\n",
      "Gradient: 5.875617e-06 Loss: 1.9029180696369014e-07\n",
      "Gradient: 2.7648575e-06 Loss: 2.0278029637665896e-07\n",
      "Gradient: 7.448374e-06 Loss: 1.9423133134447805e-07\n",
      "Gradient: 2.1251653e-06 Loss: 1.957527715035212e-07\n",
      "Gradient: 2.0193183e-06 Loss: 1.9551427404470209e-07\n",
      "Gradient: 1.9660515e-06 Loss: 1.741361610167284e-07\n",
      "Gradient: 9.894432e-07 Loss: 1.7557798841494333e-07\n",
      "Gradient: 3.186825e-06 Loss: 1.7778056857764568e-07\n",
      "Gradient: 2.9872826e-06 Loss: 1.8686312846701488e-07\n",
      "Gradient: 1.3605862e-06 Loss: 1.9637714127422138e-07\n",
      "Gradient: 3.5061607e-06 Loss: 1.8251489706244683e-07\n",
      "Gradient: 1.0223092e-06 Loss: 1.830483727853031e-07\n",
      "Gradient: 4.365436e-06 Loss: 2.407342051924388e-07\n",
      "Gradient: 1.4203463e-06 Loss: 1.8763508293773157e-07\n",
      "Gradient: 2.0621278e-06 Loss: 1.9599113064335444e-07\n",
      "Gradient: 8.9415687e-07 Loss: 1.6205627583569064e-07\n",
      "Gradient: 5.743566e-07 Loss: 1.6616620020689274e-07\n",
      "Gradient: 1.4400377e-06 Loss: 1.846379224919777e-07\n",
      "Gradient: 4.4696226e-06 Loss: 1.980687540500033e-07\n",
      "Gradient: 6.8795055e-07 Loss: 1.9416312587357729e-07\n",
      "Gradient: 3.2772182e-06 Loss: 1.901781738903689e-07\n",
      "Gradient: 1.0858473e-06 Loss: 1.821287459809658e-07\n",
      "Gradient: 1.1713278e-06 Loss: 1.688227927824452e-07\n",
      "Gradient: 5.606721e-06 Loss: 2.1881108906995906e-07\n",
      "Gradient: 1.1209728e-06 Loss: 1.956958728991746e-07\n",
      "Gradient: 1.603699e-06 Loss: 1.726601974875545e-07\n",
      "Gradient: 1.0155984e-05 Loss: 1.8521680402727725e-07\n",
      "Gradient: 9.7459e-07 Loss: 1.5708358394779983e-07\n",
      "Gradient: 5.849745e-06 Loss: 2.467627984022632e-07\n",
      "Gradient: 3.7525652e-07 Loss: 1.732505859071883e-07\n",
      "Gradient: 1.4066964e-06 Loss: 1.6230603326524335e-07\n",
      "Gradient: 3.1984964e-06 Loss: 1.97694155682863e-07\n",
      "Gradient: 1.3233081e-06 Loss: 1.686412403500981e-07\n",
      "Gradient: 2.339027e-06 Loss: 1.6323701383195535e-07\n",
      "Gradient: 1.0845764e-06 Loss: 1.7732645218870857e-07\n",
      "Gradient: 2.985454e-06 Loss: 1.53075904781493e-07\n",
      "Gradient: 4.5349175e-06 Loss: 1.9599109843208377e-07\n",
      "Gradient: 2.254542e-06 Loss: 1.7314843271757734e-07\n",
      "Gradient: 3.0631072e-06 Loss: 2.1153366702719723e-07\n",
      "Gradient: 5.9534113e-07 Loss: 1.6268068089668e-07\n",
      "Gradient: 1.9434435e-06 Loss: 1.9253962998770173e-07\n",
      "Gradient: 1.4735451e-06 Loss: 1.634639815506489e-07\n",
      "Gradient: 7.1466743e-06 Loss: 2.1593866392777272e-07\n",
      "Gradient: 1.6991469e-06 Loss: 1.8975822655420415e-07\n",
      "Gradient: 1.0185273e-06 Loss: 1.3622768193499724e-07\n",
      "Gradient: 1.4031825e-06 Loss: 1.8451305029050975e-07\n",
      "Gradient: 1.0765395e-06 Loss: 1.7523734072710794e-07\n",
      "Gradient: 1.4012357e-06 Loss: 1.82469430853871e-07\n",
      "Gradient: 1.97046e-06 Loss: 1.760207335147849e-07\n",
      "Gradient: 6.4906743e-07 Loss: 1.8842986880448127e-07\n",
      "Gradient: 4.6594237e-06 Loss: 1.978984613515422e-07\n",
      "Gradient: 3.79728e-06 Loss: 1.849784837304469e-07\n",
      "Gradient: 1.497349e-06 Loss: 2.1811853467094504e-07\n",
      "Gradient: 1.4066388e-06 Loss: 1.8400207816663775e-07\n",
      "Gradient: 5.7526313e-07 Loss: 1.5593688544868202e-07\n",
      "Gradient: 5.2931496e-06 Loss: 2.0559597212847318e-07\n",
      "Gradient: 4.6297546e-07 Loss: 1.637365751131862e-07\n",
      "Gradient: 2.9434368e-06 Loss: 1.8436540282588492e-07\n",
      "Gradient: 1.7202156e-06 Loss: 1.6995820999454737e-07\n",
      "Gradient: 2.071921e-06 Loss: 1.674037027517746e-07\n",
      "Gradient: 8.344359e-07 Loss: 1.787682156380773e-07\n",
      "Gradient: 1.8698616e-06 Loss: 1.8167473096279233e-07\n",
      "Gradient: 7.3103746e-07 Loss: 1.710480826015252e-07\n",
      "Gradient: 3.1518748e-06 Loss: 1.797672827782056e-07\n",
      "Gradient: 2.9228847e-06 Loss: 1.8685180028417865e-07\n",
      "Gradient: 1.3249023e-06 Loss: 1.9232402005779175e-07\n",
      "Gradient: 1.3219985e-06 Loss: 1.9308473753198996e-07\n",
      "Gradient: 3.19107e-06 Loss: 2.015882003547631e-07\n",
      "Gradient: 5.6844656e-06 Loss: 2.184478660183231e-07\n",
      "Gradient: 1.2973526e-06 Loss: 1.9652475960659406e-07\n",
      "Gradient: 9.3485494e-07 Loss: 1.5840055217116363e-07\n",
      "Gradient: 1.122911e-06 Loss: 1.6849359975405303e-07\n",
      "Gradient: 1.0944718e-06 Loss: 1.6792586118678325e-07\n",
      "Gradient: 3.2406965e-06 Loss: 1.6609801226271277e-07\n",
      "Gradient: 2.2023974e-06 Loss: 1.9495801405848094e-07\n",
      "Gradient: 3.0833758e-06 Loss: 1.959343011985008e-07\n",
      "Gradient: 4.892603e-06 Loss: 1.725807123875711e-07\n",
      "Gradient: 9.0386527e-07 Loss: 2.014065837367222e-07\n",
      "Gradient: 9.167848e-07 Loss: 1.7352304174285867e-07\n",
      "Gradient: 2.0489015e-06 Loss: 1.73057585565554e-07\n",
      "Gradient: 2.3723323e-06 Loss: 1.8081183033776446e-07\n",
      "Gradient: 1.3962459e-06 Loss: 1.544950301024528e-07\n",
      "Gradient: 1.7074562e-06 Loss: 1.7659972589475122e-07\n",
      "Gradient: 1.6014287e-06 Loss: 2.060045910449541e-07\n",
      "Gradient: 5.9951353e-06 Loss: 2.404845248567729e-07\n",
      "Gradient: 4.6843587e-07 Loss: 1.9613876022598713e-07\n",
      "Gradient: 1.0257669e-06 Loss: 1.7927906128534233e-07\n",
      "Gradient: 2.0384573e-06 Loss: 2.4457153292208507e-07\n",
      "Gradient: 6.9489573e-07 Loss: 1.8350258059740555e-07\n",
      "Gradient: 1.0425038e-06 Loss: 1.7092315971467542e-07\n",
      "Gradient: 2.4067444e-06 Loss: 1.9050756255486098e-07\n",
      "Gradient: 1.2137775e-06 Loss: 1.849784680985067e-07\n",
      "Gradient: 1.664937e-06 Loss: 1.53053183519584e-07\n",
      "Gradient: 1.2511653e-06 Loss: 1.8528502276164243e-07\n",
      "Gradient: 6.2561855e-07 Loss: 1.7480578300421713e-07\n",
      "Gradient: 8.9817775e-07 Loss: 1.735570731871879e-07\n",
      "Gradient: 9.0666015e-07 Loss: 1.6609804352659314e-07\n",
      "Gradient: 4.106253e-06 Loss: 1.9628629483274077e-07\n",
      "Gradient: 2.2734134e-06 Loss: 1.5651591880327942e-07\n",
      "Gradient: 6.5456493e-07 Loss: 1.7900668278040636e-07\n",
      "Gradient: 3.700384e-06 Loss: 1.8544399319845675e-07\n",
      "Gradient: 2.253561e-06 Loss: 1.7998299905267838e-07\n",
      "Gradient: 1.8369182e-06 Loss: 1.6214707609189343e-07\n",
      "Gradient: 3.85201e-06 Loss: 1.9377725664071476e-07\n",
      "Gradient: 1.2704068e-06 Loss: 1.7311438398337487e-07\n",
      "Gradient: 4.304389e-06 Loss: 2.042222516725663e-07\n",
      "Gradient: 1.5311928e-06 Loss: 2.331501266420825e-07\n",
      "Gradient: 2.0966527e-06 Loss: 2.0960353547631408e-07\n",
      "Gradient: 6.123807e-07 Loss: 1.9915863968359797e-07\n",
      "Gradient: 3.8263265e-06 Loss: 1.7460161553610001e-07\n",
      "Gradient: 4.70626e-06 Loss: 1.9169950699430652e-07\n",
      "Gradient: 6.364947e-07 Loss: 1.598310637026164e-07\n",
      "Gradient: 3.1267243e-06 Loss: 1.7194498009113582e-07\n",
      "Gradient: 1.1265366e-06 Loss: 1.8203793340868895e-07\n",
      "Gradient: 1.2069286e-06 Loss: 1.7244453971443362e-07\n",
      "Gradient: 3.1374548e-06 Loss: 1.8217425197993484e-07\n",
      "Gradient: 3.429717e-06 Loss: 1.5866158638762803e-07\n",
      "Gradient: 3.80537e-06 Loss: 1.7990361106020222e-07\n",
      "Gradient: 6.527771e-07 Loss: 2.0756008301721824e-07\n",
      "Gradient: 1.0053105e-06 Loss: 1.5093006714058295e-07\n",
      "Gradient: 1.5807371e-06 Loss: 1.7372733012166465e-07\n",
      "Gradient: 1.713568e-06 Loss: 1.8569373783824024e-07\n",
      "Gradient: 2.3817289e-07 Loss: 1.6118200344787206e-07\n",
      "Gradient: 1.0058388e-06 Loss: 1.70741577676381e-07\n",
      "Gradient: 2.3674193e-06 Loss: 1.8520559261029727e-07\n",
      "Gradient: 2.8375475e-06 Loss: 1.6881145678363889e-07\n",
      "Gradient: 5.2797313e-06 Loss: 1.7217200015314423e-07\n",
      "Gradient: 2.393172e-07 Loss: 1.6303269655774482e-07\n",
      "Gradient: 1.6833317e-06 Loss: 2.0883150095111584e-07\n",
      "Gradient: 4.0794203e-06 Loss: 1.7603209888269095e-07\n",
      "Gradient: 1.5805549e-06 Loss: 1.8048265673087372e-07\n",
      "Gradient: 2.3689317e-06 Loss: 2.0047563348650025e-07\n",
      "Gradient: 4.686247e-06 Loss: 2.1061392298330855e-07\n",
      "Gradient: 1.0446151e-06 Loss: 1.7881365176701063e-07\n",
      "Gradient: 6.3211473e-07 Loss: 1.575377339690931e-07\n",
      "Gradient: 9.2835865e-07 Loss: 1.8694252309122325e-07\n",
      "Gradient: 6.1390045e-07 Loss: 1.8275326828150657e-07\n",
      "Gradient: 2.4465069e-06 Loss: 1.7052582137466744e-07\n",
      "Gradient: 3.4793904e-06 Loss: 2.3568211323284535e-07\n",
      "Gradient: 3.3373652e-07 Loss: 1.878735076843441e-07\n",
      "Gradient: 3.410975e-06 Loss: 2.0003289975534243e-07\n",
      "Gradient: 1.1953097e-06 Loss: 1.5975151844334807e-07\n",
      "Gradient: 2.8866685e-07 Loss: 1.7862060464797953e-07\n",
      "Gradient: 1.2770802e-06 Loss: 1.6881149396870873e-07\n",
      "Gradient: 9.807615e-07 Loss: 1.636684650918596e-07\n",
      "Gradient: 2.455389e-07 Loss: 1.7552117128616374e-07\n",
      "Gradient: 7.826053e-07 Loss: 1.9057564439132573e-07\n",
      "Gradient: 3.1190184e-06 Loss: 1.7264887806807867e-07\n",
      "Gradient: 6.954358e-07 Loss: 1.7159299072015227e-07\n",
      "Gradient: 1.5243922e-06 Loss: 1.85739140571665e-07\n",
      "Gradient: 5.000108e-07 Loss: 1.9775084183493164e-07\n",
      "Gradient: 1.5116275e-06 Loss: 1.6398632768736358e-07\n",
      "Gradient: 9.715033e-07 Loss: 1.8607967670429085e-07\n",
      "Gradient: 1.8000724e-06 Loss: 2.0433576253253705e-07\n",
      "Gradient: 7.142257e-06 Loss: 1.7624777702470357e-07\n",
      "Gradient: 9.040692e-07 Loss: 1.6504209507199145e-07\n",
      "Gradient: 4.389408e-06 Loss: 1.9575262880285512e-07\n",
      "Gradient: 2.3159546e-06 Loss: 1.8108427492317485e-07\n",
      "Gradient: 2.4624671e-06 Loss: 2.0005559520086535e-07\n",
      "Gradient: 6.230937e-07 Loss: 1.8768049490821188e-07\n",
      "Gradient: 3.73839e-07 Loss: 2.0391566704821192e-07\n",
      "Gradient: 3.1895513e-06 Loss: 1.9038266808972065e-07\n",
      "Gradient: 1.1021441e-06 Loss: 1.825034154023797e-07\n",
      "Gradient: 1.1745093e-06 Loss: 1.7990362740268515e-07\n",
      "Gradient: 3.423525e-06 Loss: 1.839566965126475e-07\n",
      "Gradient: 3.663319e-07 Loss: 1.9667217922384833e-07\n",
      "Gradient: 1.8960632e-06 Loss: 2.1113621926360792e-07\n",
      "Gradient: 1.8503115e-06 Loss: 1.64451782325159e-07\n",
      "Gradient: 4.4712087e-06 Loss: 1.7184282820418655e-07\n",
      "Gradient: 7.699513e-07 Loss: 1.8477411861302547e-07\n",
      "Gradient: 1.0600066e-06 Loss: 1.922445643269081e-07\n",
      "Gradient: 1.1332245e-05 Loss: 2.1476913213784126e-07\n",
      "Gradient: 6.4041774e-07 Loss: 1.6213582512136782e-07\n",
      "Gradient: 3.5285854e-07 Loss: 1.6974243877143635e-07\n",
      "Gradient: 2.398538e-06 Loss: 1.8696534264487734e-07\n",
      "Gradient: 6.266862e-07 Loss: 1.8286670666611826e-07\n",
      "Gradient: 1.3730123e-06 Loss: 1.7356844968693016e-07\n",
      "Gradient: 4.084572e-07 Loss: 1.8494449918193823e-07\n",
      "Gradient: 8.8121345e-07 Loss: 1.6929970385604066e-07\n",
      "Gradient: 5.702679e-06 Loss: 1.8148163197414154e-07\n",
      "Gradient: 3.348547e-07 Loss: 1.6705169538037506e-07\n",
      "Gradient: 6.910309e-07 Loss: 1.8981492549604203e-07\n",
      "Gradient: 3.4397904e-06 Loss: 2.5276872648305473e-07\n",
      "Gradient: 6.9388864e-07 Loss: 2.1120444534024804e-07\n",
      "Gradient: 7.3180064e-07 Loss: 1.7312575456192766e-07\n",
      "Gradient: 3.221716e-06 Loss: 2.1761908991872284e-07\n",
      "Gradient: 2.6777577e-06 Loss: 1.7603210788289896e-07\n",
      "Gradient: 2.8437591e-06 Loss: 1.6471291222804514e-07\n",
      "Gradient: 5.391918e-07 Loss: 1.9310744410934907e-07\n",
      "Gradient: 8.6363326e-07 Loss: 1.8923597195907859e-07\n",
      "Gradient: 7.572849e-07 Loss: 1.7671331420388015e-07\n",
      "Gradient: 2.5454588e-06 Loss: 1.7162704324391598e-07\n",
      "Gradient: 9.983222e-07 Loss: 1.7589587244515315e-07\n",
      "Gradient: 1.5882239e-06 Loss: 1.990338117726272e-07\n",
      "Gradient: 1.3737708e-06 Loss: 1.63350607351731e-07\n",
      "Gradient: 2.4863725e-06 Loss: 1.8474009190564782e-07\n",
      "Gradient: 3.4865764e-06 Loss: 1.472290056388677e-07\n",
      "Gradient: 3.6519762e-06 Loss: 1.6699490051526785e-07\n",
      "Gradient: 3.5109038e-06 Loss: 1.8401339427024747e-07\n",
      "Gradient: 1.6196164e-07 Loss: 1.7466975072248184e-07\n",
      "Gradient: 2.0835519e-06 Loss: 2.00713863070708e-07\n",
      "Gradient: 8.2205537e-07 Loss: 1.8476278048259095e-07\n",
      "Gradient: 1.0810832e-06 Loss: 1.8604573786736486e-07\n",
      "Gradient: 1.0185998e-06 Loss: 1.7910882803562346e-07\n",
      "Gradient: 2.2547724e-07 Loss: 1.6781238443286384e-07\n",
      "Gradient: 1.726635e-06 Loss: 1.7388638724469273e-07\n",
      "Gradient: 8.487584e-07 Loss: 1.7812115752728155e-07\n",
      "Gradient: 1.1143869e-06 Loss: 1.7841625350456524e-07\n",
      "Gradient: 7.7859215e-07 Loss: 1.834911510438057e-07\n",
      "Gradient: 1.4188881e-06 Loss: 1.8175418337780986e-07\n",
      "Gradient: 4.8791494e-06 Loss: 1.8786202010308747e-07\n",
      "Gradient: 1.4418333e-06 Loss: 1.6380472563544876e-07\n",
      "Gradient: 3.6317342e-06 Loss: 1.733754065943079e-07\n",
      "Gradient: 1.0523761e-06 Loss: 1.7581644395174105e-07\n",
      "Gradient: 6.2207323e-07 Loss: 1.547219869261577e-07\n",
      "Gradient: 2.0708147e-07 Loss: 1.8317322982852602e-07\n",
      "Gradient: 8.214435e-07 Loss: 1.5255368121340022e-07\n",
      "Gradient: 6.9722404e-07 Loss: 1.884411207223972e-07\n",
      "Gradient: 6.865655e-07 Loss: 1.5776474218872257e-07\n",
      "Gradient: 1.5637893e-06 Loss: 1.872605153607765e-07\n",
      "Gradient: 1.9992494e-06 Loss: 1.8221965293700276e-07\n",
      "Gradient: 1.6543686e-06 Loss: 2.082525554669701e-07\n",
      "Gradient: 2.2633753e-06 Loss: 1.7600933664615088e-07\n",
      "Gradient: 8.967563e-07 Loss: 1.730121487260779e-07\n",
      "Gradient: 8.6966196e-07 Loss: 1.9243751031202313e-07\n",
      "Gradient: 1.4217601e-06 Loss: 1.7168384142488927e-07\n",
      "Gradient: 1.0694663e-07 Loss: 1.5904768417840388e-07\n",
      "Gradient: 1.9518288e-06 Loss: 1.7200169158589536e-07\n",
      "Gradient: 6.27377e-07 Loss: 1.7707662086271133e-07\n",
      "Gradient: 5.1338935e-07 Loss: 1.739772121330437e-07\n",
      "Gradient: 4.928222e-07 Loss: 1.5406352199912968e-07\n",
      "Gradient: 3.7400778e-06 Loss: 1.695380473639337e-07\n",
      "Gradient: 4.391933e-06 Loss: 1.982958572455118e-07\n",
      "Gradient: 1.2048422e-06 Loss: 1.6472435883467067e-07\n",
      "Gradient: 6.8696295e-07 Loss: 1.793473354420409e-07\n",
      "Gradient: 9.443316e-07 Loss: 2.1071619068872375e-07\n",
      "Gradient: 1.557794e-06 Loss: 1.668813898921447e-07\n",
      "Gradient: 2.3225637e-06 Loss: 1.6975369637369416e-07\n",
      "Gradient: 2.681878e-06 Loss: 1.9785305719703197e-07\n",
      "Gradient: 9.442152e-07 Loss: 1.655531339868806e-07\n",
      "Gradient: 4.8031566e-06 Loss: 1.8317333001505175e-07\n",
      "Gradient: 1.1876284e-06 Loss: 1.5799184656846896e-07\n",
      "Gradient: 6.651645e-07 Loss: 1.8299171339701085e-07\n",
      "Gradient: 5.673709e-07 Loss: 1.7956299510994237e-07\n",
      "Gradient: 1.0293331e-06 Loss: 1.5752633970578244e-07\n",
      "Gradient: 1.063677e-06 Loss: 1.6079613989935145e-07\n",
      "Gradient: 1.6865374e-06 Loss: 1.7219479270617436e-07\n",
      "Gradient: 1.7921958e-06 Loss: 1.6364570380270985e-07\n",
      "Gradient: 7.0747836e-07 Loss: 1.7852985176129247e-07\n",
      "Gradient: 3.5840347e-07 Loss: 1.7002620259868687e-07\n",
      "Gradient: 1.4113448e-06 Loss: 1.7930195876184976e-07\n",
      "Gradient: 2.0650273e-07 Loss: 1.956392329323838e-07\n",
      "Gradient: 2.985369e-07 Loss: 1.650535345731896e-07\n",
      "Gradient: 1.3926364e-06 Loss: 1.9823909743384624e-07\n",
      "Gradient: 2.2351405e-06 Loss: 1.8703338990159562e-07\n",
      "Gradient: 7.7225786e-07 Loss: 1.7209251505316084e-07\n",
      "Gradient: 4.3288687e-06 Loss: 1.7351178674592423e-07\n",
      "Gradient: 9.773344e-07 Loss: 1.5672023820911817e-07\n",
      "Gradient: 4.5340257e-06 Loss: 1.9901097729757567e-07\n",
      "Gradient: 2.463546e-06 Loss: 1.9418591013694215e-07\n",
      "Gradient: 4.5061978e-07 Loss: 2.05959238523216e-07\n",
      "Gradient: 1.74711e-06 Loss: 1.8276454577896099e-07\n",
      "Gradient: 5.9462667e-07 Loss: 1.750897709484889e-07\n",
      "Gradient: 3.0999684e-06 Loss: 1.7298939809506918e-07\n",
      "Gradient: 1.2847182e-06 Loss: 1.8160652549189156e-07\n",
      "Gradient: 1.1867244e-06 Loss: 1.7577088584630474e-07\n",
      "Gradient: 3.9123813e-07 Loss: 1.6817569701288448e-07\n",
      "Gradient: 1.2899775e-06 Loss: 1.501694706954974e-07\n",
      "Gradient: 3.2754542e-06 Loss: 2.3221928439435638e-07\n",
      "Gradient: 2.1698797e-06 Loss: 1.851487255066786e-07\n",
      "Gradient: 1.9116342e-06 Loss: 1.7800762369309572e-07\n",
      "Gradient: 1.8046081e-06 Loss: 1.5412038697112015e-07\n",
      "Gradient: 9.2942344e-07 Loss: 1.7689500400782284e-07\n",
      "Gradient: 4.6713566e-07 Loss: 1.595358421961161e-07\n",
      "Gradient: 1.4424877e-06 Loss: 1.7303480935500676e-07\n",
      "Gradient: 1.4236465e-06 Loss: 2.0465338366193463e-07\n",
      "Gradient: 3.323895e-07 Loss: 1.7054851089900088e-07\n",
      "Gradient: 4.4884462e-07 Loss: 1.6204493403411864e-07\n",
      "Gradient: 8.5506645e-07 Loss: 1.7445412889098104e-07\n",
      "Gradient: 5.538197e-07 Loss: 1.9812551196688825e-07\n",
      "Gradient: 5.432351e-07 Loss: 1.5958129537807508e-07\n",
      "Gradient: 1.0554695e-06 Loss: 1.7758745514129258e-07\n",
      "Gradient: 2.9742703e-06 Loss: 1.8724921299432632e-07\n",
      "Gradient: 2.7995277e-06 Loss: 1.5954724403854924e-07\n",
      "Gradient: 2.6366097e-06 Loss: 2.1075030076644907e-07\n",
      "Gradient: 5.7308773e-07 Loss: 1.8419512386458338e-07\n",
      "Gradient: 1.0213892e-06 Loss: 1.692655861991928e-07\n",
      "Gradient: 1.1433544e-06 Loss: 1.7138848633635463e-07\n",
      "Gradient: 1.4487941e-06 Loss: 1.866020961453311e-07\n",
      "Gradient: 1.2317446e-06 Loss: 1.7199044179960766e-07\n",
      "Gradient: 7.081471e-07 Loss: 1.779280440909285e-07\n",
      "Gradient: 5.4321777e-07 Loss: 1.6943589737176504e-07\n",
      "Gradient: 3.8346e-06 Loss: 1.9130221176055784e-07\n",
      "Gradient: 3.5330277e-06 Loss: 1.7322781881527286e-07\n",
      "Gradient: 2.6879343e-06 Loss: 1.9549150943968623e-07\n",
      "Gradient: 1.2229982e-06 Loss: 1.501694318524945e-07\n",
      "Gradient: 1.3795586e-06 Loss: 1.7303492398923482e-07\n",
      "Gradient: 2.2929767e-06 Loss: 1.7610025532614296e-07\n",
      "Gradient: 2.2421138e-07 Loss: 1.765090046272159e-07\n",
      "Gradient: 6.8130817e-07 Loss: 1.671653350854285e-07\n",
      "Gradient: 2.0948578e-06 Loss: 1.7815519631388573e-07\n",
      "Gradient: 4.2602537e-07 Loss: 1.6266933921353182e-07\n",
      "Gradient: 1.7376067e-06 Loss: 1.53268784449286e-07\n",
      "Gradient: 2.7957892e-06 Loss: 1.9486718159100746e-07\n",
      "Gradient: 1.3354008e-06 Loss: 1.8410420921100012e-07\n",
      "Gradient: 2.7464732e-06 Loss: 1.6917472720479054e-07\n",
      "Gradient: 1.736563e-06 Loss: 2.1382701641906958e-07\n",
      "Gradient: 1.1831888e-06 Loss: 1.7521467915078878e-07\n",
      "Gradient: 2.942714e-07 Loss: 1.7514652036846693e-07\n",
      "Gradient: 4.094526e-06 Loss: 1.8086851980569917e-07\n",
      "Gradient: 1.386453e-06 Loss: 1.7107083039036297e-07\n",
      "Gradient: 1.0343582e-06 Loss: 1.7440867689325993e-07\n",
      "Gradient: 7.5721425e-07 Loss: 1.8581856764399163e-07\n",
      "Gradient: 1.5333908e-06 Loss: 1.7038958759485469e-07\n",
      "Gradient: 1.8844629e-06 Loss: 1.8713550732722222e-07\n",
      "Gradient: 5.9020715e-07 Loss: 2.1306635768307086e-07\n",
      "Gradient: 2.1036785e-06 Loss: 1.9892023459533447e-07\n",
      "Gradient: 3.2854618e-07 Loss: 1.8777126105836336e-07\n",
      "Gradient: 2.309808e-07 Loss: 1.8776009274764268e-07\n",
      "Gradient: 1.6681914e-06 Loss: 1.985910391984665e-07\n",
      "Gradient: 6.7940186e-07 Loss: 1.7906349469853922e-07\n",
      "Gradient: 1.4848e-06 Loss: 1.8397933179888544e-07\n",
      "Gradient: 4.6802006e-07 Loss: 1.6382743600236912e-07\n",
      "Gradient: 3.0266206e-06 Loss: 1.9680866335155162e-07\n",
      "Gradient: 1.8158568e-06 Loss: 1.7951758432369995e-07\n",
      "Gradient: 9.3160537e-07 Loss: 1.7452210296179753e-07\n",
      "Gradient: 3.277529e-07 Loss: 1.6878877791744648e-07\n",
      "Gradient: 1.9935364e-06 Loss: 1.8852054542624804e-07\n",
      "Gradient: 3.77791e-06 Loss: 1.894515828363789e-07\n",
      "Gradient: 7.4233935e-07 Loss: 1.5097556153402061e-07\n",
      "Gradient: 9.67006e-07 Loss: 1.9228999263987135e-07\n",
      "Gradient: 1.1402173e-06 Loss: 1.7092319192594612e-07\n",
      "Gradient: 1.5664896e-06 Loss: 1.724558134223268e-07\n",
      "Gradient: 7.674954e-07 Loss: 1.6828921616252047e-07\n",
      "Gradient: 1.1063858e-06 Loss: 1.8617050538220306e-07\n",
      "Gradient: 1.8286715e-06 Loss: 1.7780331068214158e-07\n",
      "Gradient: 1.1718271e-06 Loss: 1.8333225995093017e-07\n",
      "Gradient: 6.3904525e-07 Loss: 1.694131195032848e-07\n",
      "Gradient: 1.0252163e-06 Loss: 1.9366374175433522e-07\n",
      "Gradient: 7.1013505e-07 Loss: 1.8543254457862682e-07\n",
      "Gradient: 2.9626597e-07 Loss: 1.7595265073092984e-07\n",
      "Gradient: 1.0714402e-06 Loss: 1.8207202003850398e-07\n",
      "Gradient: 2.480223e-07 Loss: 1.6939042666308523e-07\n",
      "Gradient: 2.9182545e-06 Loss: 1.938453299506667e-07\n",
      "Gradient: 1.5685554e-06 Loss: 1.9048489742582813e-07\n",
      "Gradient: 4.4310758e-07 Loss: 1.7547578134250823e-07\n",
      "Gradient: 9.330322e-07 Loss: 1.6588237627956914e-07\n",
      "Gradient: 2.3133634e-06 Loss: 1.8603430428735617e-07\n",
      "Gradient: 1.4273232e-06 Loss: 2.0081620680419595e-07\n",
      "Gradient: 7.110437e-07 Loss: 1.6422479021116487e-07\n",
      "Gradient: 3.9943197e-07 Loss: 1.7566869274787679e-07\n",
      "Gradient: 3.242354e-07 Loss: 1.7779190599753747e-07\n",
      "Gradient: 9.4924786e-07 Loss: 1.904507354784831e-07\n",
      "Gradient: 1.3071706e-06 Loss: 1.7729234400576387e-07\n",
      "Gradient: 1.4604384e-06 Loss: 2.0933115933985392e-07\n",
      "Gradient: 7.551802e-07 Loss: 1.8456981744445027e-07\n",
      "Gradient: 5.864494e-07 Loss: 1.7260343554426072e-07\n",
      "Gradient: 3.024916e-07 Loss: 1.551080908749706e-07\n",
      "Gradient: 7.534023e-07 Loss: 1.919265494384111e-07\n",
      "Gradient: 2.5862535e-06 Loss: 2.185728353272983e-07\n",
      "Gradient: 4.517272e-07 Loss: 1.8265097831241898e-07\n",
      "Gradient: 1.1240313e-06 Loss: 1.691407876573218e-07\n",
      "Gradient: 1.2076468e-06 Loss: 1.8833898517793084e-07\n",
      "Gradient: 1.1792988e-06 Loss: 1.7888181034209082e-07\n",
      "Gradient: 8.706372e-07 Loss: 1.7545311171337137e-07\n",
      "Gradient: 1.9280292e-06 Loss: 1.8751024117117746e-07\n",
      "Gradient: 2.8204636e-07 Loss: 1.52985031576236e-07\n",
      "Gradient: 1.0434944e-06 Loss: 1.809140291205343e-07\n",
      "Gradient: 2.9434966e-07 Loss: 1.7958571210859494e-07\n",
      "Gradient: 7.476244e-07 Loss: 1.8914515038659373e-07\n",
      "Gradient: 1.2003926e-06 Loss: 1.6665432435540122e-07\n",
      "Gradient: 3.8516316e-07 Loss: 1.75998108886688e-07\n",
      "Gradient: 1.3736255e-06 Loss: 1.6532590407791758e-07\n",
      "Gradient: 1.6454641e-06 Loss: 1.6112534725702214e-07\n",
      "Gradient: 1.1372894e-06 Loss: 1.8765771443440825e-07\n",
      "Gradient: 2.3648938e-07 Loss: 1.5530105959745318e-07\n",
      "Gradient: 2.0728805e-06 Loss: 1.9174493672835525e-07\n",
      "Gradient: 1.600784e-07 Loss: 1.71434125325239e-07\n",
      "Gradient: 1.7387595e-06 Loss: 1.5745830310720522e-07\n",
      "Gradient: 1.125716e-06 Loss: 1.9056424065411194e-07\n",
      "Gradient: 1.5737492e-06 Loss: 1.6948133610602175e-07\n",
      "Gradient: 2.1922375e-07 Loss: 1.94583347479238e-07\n",
      "Gradient: 9.725741e-07 Loss: 1.7851851007814428e-07\n",
      "Gradient: 1.0078106e-06 Loss: 1.8757829636228963e-07\n",
      "Gradient: 2.5172294e-06 Loss: 1.7823471125666402e-07\n",
      "Gradient: 1.8336689e-06 Loss: 1.7876824784934797e-07\n",
      "Gradient: 9.3868556e-07 Loss: 1.7336411228067543e-07\n",
      "Gradient: 2.2951446e-07 Loss: 2.043584430566625e-07\n",
      "Gradient: 1.7381614e-06 Loss: 1.7153628988353377e-07\n",
      "Gradient: 8.38466e-07 Loss: 1.7615701040085696e-07\n",
      "Gradient: 2.112713e-06 Loss: 1.90076017266468e-07\n",
      "Gradient: 1.3461395e-06 Loss: 1.7845038442487747e-07\n",
      "Gradient: 1.8114723e-06 Loss: 1.966496299132814e-07\n",
      "Gradient: 8.9346406e-07 Loss: 1.65314644107184e-07\n",
      "Gradient: 1.1100017e-06 Loss: 1.817769529566249e-07\n",
      "Gradient: 8.453879e-07 Loss: 2.0711730831142934e-07\n",
      "Gradient: 9.983039e-07 Loss: 1.582301744444218e-07\n",
      "Gradient: 4.2602287e-06 Loss: 2.11942508580402e-07\n",
      "Gradient: 6.761849e-07 Loss: 1.6639326621733138e-07\n",
      "Gradient: 1.2087487e-06 Loss: 1.7464705261242369e-07\n",
      "Gradient: 1.3006479e-06 Loss: 1.7711068380776852e-07\n",
      "Gradient: 3.9169317e-06 Loss: 1.9065503972607682e-07\n",
      "Gradient: 5.655502e-07 Loss: 1.6490598563715746e-07\n",
      "Gradient: 5.319137e-07 Loss: 1.801420426753945e-07\n",
      "Gradient: 1.1799815e-06 Loss: 1.8219694955708595e-07\n",
      "Gradient: 1.4746695e-06 Loss: 2.0900185641418526e-07\n",
      "Gradient: 8.6901895e-07 Loss: 1.723424304600485e-07\n",
      "Gradient: 3.6832162e-07 Loss: 1.9192672221871968e-07\n",
      "Gradient: 7.087764e-07 Loss: 1.5399547758458236e-07\n",
      "Gradient: 2.2614095e-06 Loss: 1.8963332427309372e-07\n",
      "Gradient: 9.649059e-07 Loss: 1.9108643177408641e-07\n",
      "Gradient: 1.0958624e-06 Loss: 1.7611160008830968e-07\n",
      "Gradient: 1.3650824e-06 Loss: 1.9772807201926905e-07\n",
      "Gradient: 1.1312243e-06 Loss: 1.7846171544988466e-07\n",
      "Gradient: 1.7712621e-06 Loss: 1.9356153065549128e-07\n",
      "Gradient: 3.898855e-07 Loss: 1.644972321912519e-07\n",
      "Gradient: 7.218892e-07 Loss: 1.956617704005718e-07\n",
      "Gradient: 1.1619613e-06 Loss: 1.974782814310553e-07\n",
      "Gradient: 4.6945337e-07 Loss: 1.8124330244025563e-07\n",
      "Gradient: 3.457659e-07 Loss: 1.8492171053689313e-07\n",
      "Gradient: 1.286726e-06 Loss: 2.0625441479182883e-07\n",
      "Gradient: 7.4970517e-06 Loss: 2.168243585269162e-07\n",
      "Gradient: 1.9410297e-06 Loss: 2.0459682019691173e-07\n",
      "Gradient: 1.5500223e-06 Loss: 1.7405662144180194e-07\n",
      "Gradient: 2.6097288e-07 Loss: 1.7175189128693092e-07\n",
      "Gradient: 2.5685335e-06 Loss: 1.7319382384547073e-07\n",
      "Gradient: 9.249029e-07 Loss: 1.7464711892974568e-07\n",
      "Gradient: 1.5508838e-06 Loss: 1.9361825636110553e-07\n",
      "Gradient: 7.945992e-07 Loss: 1.833435571067336e-07\n",
      "Gradient: 2.0263242e-06 Loss: 2.1009192063085418e-07\n",
      "Gradient: 3.0444553e-06 Loss: 1.789498886258419e-07\n",
      "Gradient: 1.1285027e-06 Loss: 2.023716478542307e-07\n",
      "Gradient: 3.853039e-07 Loss: 1.8200394601800933e-07\n",
      "Gradient: 1.0379014e-06 Loss: 1.7057128663585292e-07\n",
      "Gradient: 2.1148132e-06 Loss: 1.8789619720867753e-07\n",
      "Gradient: 5.5780885e-07 Loss: 1.7019656368688628e-07\n",
      "Gradient: 1.3530524e-06 Loss: 2.0513054271494487e-07\n",
      "Gradient: 2.30152e-06 Loss: 1.7375014872792843e-07\n",
      "Gradient: 2.8719367e-06 Loss: 1.9731941852304166e-07\n",
      "Gradient: 1.2630517e-06 Loss: 1.8426326988674191e-07\n",
      "Gradient: 1.0610075e-06 Loss: 1.7515796457701072e-07\n",
      "Gradient: 1.1188557e-06 Loss: 2.1265773095061983e-07\n",
      "Gradient: 4.4411775e-07 Loss: 1.6448586848127889e-07\n",
      "Gradient: 7.985356e-07 Loss: 2.023147966193998e-07\n",
      "Gradient: 1.7112711e-06 Loss: 1.5795772488521226e-07\n",
      "Gradient: 2.3186562e-06 Loss: 1.6931094393157764e-07\n",
      "Gradient: 1.3514289e-06 Loss: 1.7761027824766035e-07\n",
      "Gradient: 1.6586681e-06 Loss: 1.993176115414978e-07\n",
      "Gradient: 1.6490097e-07 Loss: 1.5343915116261542e-07\n",
      "Gradient: 1.0612694e-06 Loss: 1.837977665767691e-07\n",
      "Gradient: 1.0057796e-06 Loss: 1.9025773501842498e-07\n",
      "Gradient: 1.1689021e-06 Loss: 1.855348095602949e-07\n",
      "Gradient: 2.3929304e-06 Loss: 1.8930401589993078e-07\n",
      "Gradient: 3.0310493e-06 Loss: 1.8761252249532844e-07\n",
      "Gradient: 2.5126974e-06 Loss: 1.7261478220120806e-07\n",
      "Gradient: 3.1728183e-07 Loss: 1.4759224396717247e-07\n",
      "Gradient: 1.541983e-06 Loss: 1.7588458121053918e-07\n",
      "Gradient: 7.689869e-07 Loss: 2.0069143265762554e-07\n",
      "Gradient: 7.2273053e-07 Loss: 1.7108211475639715e-07\n",
      "Gradient: 3.3436552e-07 Loss: 1.8231039717875318e-07\n",
      "Gradient: 9.32671e-07 Loss: 1.9337984250948162e-07\n",
      "Gradient: 1.6560389e-06 Loss: 2.0980810144048216e-07\n",
      "Gradient: 2.7895267e-06 Loss: 1.659505130646721e-07\n",
      "Gradient: 2.335701e-06 Loss: 1.7966513136495146e-07\n",
      "Gradient: 6.6714324e-07 Loss: 1.8156116207516486e-07\n",
      "Gradient: 6.782294e-07 Loss: 1.8226504323592961e-07\n",
      "Gradient: 1.822262e-06 Loss: 1.9140427459281758e-07\n",
      "Gradient: 1.6017866e-06 Loss: 2.2921076805459962e-07\n",
      "Gradient: 1.1022123e-06 Loss: 1.6118211618731947e-07\n",
      "Gradient: 3.675123e-07 Loss: 1.9255116493847405e-07\n",
      "Gradient: 9.314699e-07 Loss: 1.723649688756268e-07\n",
      "Gradient: 2.4782292e-07 Loss: 1.7124106766649068e-07\n",
      "Gradient: 8.9439663e-07 Loss: 1.750557643731554e-07\n",
      "Gradient: 1.7330366e-06 Loss: 1.8840717454319627e-07\n",
      "Gradient: 1.5488085e-06 Loss: 1.8806653135546487e-07\n",
      "Gradient: 2.5062382e-06 Loss: 2.0415399054248459e-07\n",
      "Gradient: 2.4250795e-07 Loss: 1.9337982143004714e-07\n",
      "Gradient: 2.4266933e-07 Loss: 1.7029866938855776e-07\n",
      "Gradient: 2.4333813e-06 Loss: 1.578101695542955e-07\n",
      "Gradient: 3.4846084e-06 Loss: 2.0935393033975439e-07\n",
      "Gradient: 7.598994e-07 Loss: 1.6400905143617212e-07\n",
      "Gradient: 1.244247e-06 Loss: 1.9099557941141635e-07\n",
      "Gradient: 1.4133403e-06 Loss: 1.858525986146257e-07\n",
      "Gradient: 8.92785e-07 Loss: 1.6900444990142205e-07\n",
      "Gradient: 3.1782424e-06 Loss: 1.9235814789908546e-07\n",
      "Gradient: 2.9282882e-07 Loss: 1.658482939130105e-07\n",
      "Gradient: 2.5599866e-06 Loss: 1.805733826169368e-07\n",
      "Gradient: 8.525957e-07 Loss: 1.754417719250038e-07\n",
      "Gradient: 1.122994e-06 Loss: 1.6104584238026595e-07\n",
      "Gradient: 1.1179682e-06 Loss: 1.598083227823584e-07\n",
      "Gradient: 1.6583415e-06 Loss: 1.8259423958018792e-07\n",
      "Gradient: 1.0937457e-06 Loss: 1.892586363775687e-07\n",
      "Gradient: 1.7255725e-06 Loss: 2.3450143042206642e-07\n",
      "Gradient: 5.0735133e-07 Loss: 1.8848658290456417e-07\n",
      "Gradient: 4.777762e-07 Loss: 1.7325059976277164e-07\n",
      "Gradient: 7.9651136e-07 Loss: 1.9834126400534538e-07\n",
      "Gradient: 9.1611673e-07 Loss: 1.6900449561300472e-07\n",
      "Gradient: 1.4430764e-06 Loss: 1.7309161772042597e-07\n",
      "Gradient: 9.798882e-07 Loss: 1.6722193431443582e-07\n",
      "Gradient: 6.9172e-07 Loss: 1.7243318760999198e-07\n",
      "Gradient: 6.964281e-07 Loss: 1.9630898104120812e-07\n",
      "Gradient: 2.7414042e-06 Loss: 1.9048483181904886e-07\n",
      "Gradient: 4.8746335e-07 Loss: 1.6789187995414068e-07\n",
      "Gradient: 7.913941e-06 Loss: 2.086839685944142e-07\n",
      "Gradient: 1.0793351e-06 Loss: 1.8488766334219994e-07\n",
      "Gradient: 8.465256e-07 Loss: 1.8795289449258235e-07\n",
      "Gradient: 7.2361854e-07 Loss: 1.831392656489091e-07\n",
      "Gradient: 7.1057536e-07 Loss: 1.95253136799541e-07\n",
      "Gradient: 3.0615774e-07 Loss: 1.692429028328964e-07\n",
      "Gradient: 4.6504826e-07 Loss: 1.7273970544332922e-07\n",
      "Gradient: 5.1692246e-07 Loss: 1.445155381437265e-07\n",
      "Gradient: 1.4032873e-06 Loss: 1.9936304530195532e-07\n",
      "Gradient: 1.046378e-06 Loss: 1.5534658407053333e-07\n",
      "Gradient: 3.4731278e-07 Loss: 1.6664302269949378e-07\n",
      "Gradient: 1.0727496e-06 Loss: 1.7092323811122394e-07\n",
      "Gradient: 1.760737e-06 Loss: 1.6276021005031302e-07\n",
      "Gradient: 2.764076e-07 Loss: 1.845811607855315e-07\n",
      "Gradient: 1.4161164e-06 Loss: 1.9978299832246192e-07\n",
      "Gradient: 1.6072581e-06 Loss: 2.039495100802924e-07\n",
      "Gradient: 7.6675116e-07 Loss: 1.8043706262460546e-07\n",
      "Gradient: 1.1193761e-06 Loss: 1.808232276800936e-07\n",
      "Gradient: 2.561732e-06 Loss: 1.8480814579409828e-07\n",
      "Gradient: 1.2697723e-06 Loss: 1.9601387748480193e-07\n",
      "Gradient: 6.765248e-07 Loss: 1.7863204580711073e-07\n",
      "Gradient: 2.2076802e-06 Loss: 1.7692902763618196e-07\n",
      "Gradient: 2.0508114e-06 Loss: 1.9812557141563048e-07\n",
      "Gradient: 3.231068e-07 Loss: 1.6608668929052328e-07\n",
      "Gradient: 9.475014e-07 Loss: 1.62374204511669e-07\n",
      "Gradient: 3.5309176e-07 Loss: 1.9228998624498672e-07\n",
      "Gradient: 2.4456788e-06 Loss: 1.9048467407856152e-07\n",
      "Gradient: 8.624047e-07 Loss: 1.8047107713433282e-07\n",
      "Gradient: 4.850798e-07 Loss: 1.6428154315425065e-07\n",
      "Gradient: 8.239349e-07 Loss: 1.884298718834998e-07\n",
      "Gradient: 1.7113807e-06 Loss: 1.9302796848326881e-07\n",
      "Gradient: 1.7471909e-06 Loss: 1.826736858371684e-07\n",
      "Gradient: 1.939258e-06 Loss: 1.779620977989301e-07\n",
      "Gradient: 7.2109515e-07 Loss: 1.5472211979764932e-07\n",
      "Gradient: 8.964847e-07 Loss: 1.9951048765657712e-07\n",
      "Gradient: 2.321687e-06 Loss: 1.532347437679012e-07\n",
      "Gradient: 5.790812e-07 Loss: 1.9980576766442936e-07\n",
      "Gradient: 1.9247154e-06 Loss: 1.844335426900064e-07\n",
      "Gradient: 6.428247e-07 Loss: 1.567543516027096e-07\n",
      "Gradient: 8.7904914e-07 Loss: 1.9113194795750133e-07\n",
      "Gradient: 3.193071e-07 Loss: 1.725466840222604e-07\n",
      "Gradient: 1.3071002e-06 Loss: 1.6343004508219868e-07\n",
      "Gradient: 2.810857e-06 Loss: 2.031890585859249e-07\n",
      "Gradient: 3.2491323e-07 Loss: 1.768155006705759e-07\n",
      "Gradient: 4.185705e-06 Loss: 1.8422907572812618e-07\n",
      "Gradient: 7.2384717e-07 Loss: 2.1271436736469696e-07\n",
      "Gradient: 5.376427e-07 Loss: 1.7790547299038432e-07\n",
      "Gradient: 5.436759e-07 Loss: 1.8360478198549875e-07\n",
      "Gradient: 1.4165556e-07 Loss: 1.9278949565659785e-07\n",
      "Gradient: 1.302119e-06 Loss: 1.8824818113216679e-07\n",
      "Gradient: 6.244737e-07 Loss: 1.6441771156413172e-07\n",
      "Gradient: 7.084067e-07 Loss: 1.8612506380577543e-07\n",
      "Gradient: 1.9050945e-06 Loss: 2.2490790006675827e-07\n",
      "Gradient: 2.7672709e-06 Loss: 1.9634306530254738e-07\n",
      "Gradient: 1.7864426e-07 Loss: 1.8321872043240244e-07\n",
      "Gradient: 1.4879188e-06 Loss: 2.053007875701951e-07\n",
      "Gradient: 2.2657883e-07 Loss: 2.006346096076565e-07\n",
      "Gradient: 1.7269481e-06 Loss: 2.2578214474341014e-07\n",
      "Gradient: 2.0369534e-06 Loss: 1.7681544809041346e-07\n",
      "Gradient: 2.135994e-06 Loss: 2.147125679622756e-07\n",
      "Gradient: 4.0171162e-07 Loss: 1.790634816719224e-07\n",
      "Gradient: 2.5442491e-06 Loss: 1.8825958842209426e-07\n",
      "Gradient: 4.2638617e-06 Loss: 2.1980995962659714e-07\n",
      "Gradient: 4.2630327e-07 Loss: 1.6170429499121988e-07\n",
      "Gradient: 6.426077e-07 Loss: 1.8677230192073088e-07\n",
      "Gradient: 1.239957e-06 Loss: 1.6800539673530087e-07\n",
      "Gradient: 1.8008193e-06 Loss: 1.7582770581725526e-07\n",
      "Gradient: 3.5530513e-07 Loss: 1.8063016185010384e-07\n",
      "Gradient: 2.0043735e-06 Loss: 1.7831406064298488e-07\n",
      "Gradient: 1.3699664e-06 Loss: 1.7655445153271406e-07\n",
      "Gradient: 1.8311624e-06 Loss: 1.856028750542767e-07\n",
      "Gradient: 1.8225471e-06 Loss: 1.9621823454940568e-07\n",
      "Gradient: 6.8691963e-07 Loss: 1.820606892503444e-07\n",
      "Gradient: 1.2560924e-06 Loss: 1.9140442238570662e-07\n",
      "Gradient: 1.5816855e-06 Loss: 1.9575262323693703e-07\n",
      "Gradient: 1.8558697e-07 Loss: 1.6216974572103026e-07\n",
      "Gradient: 3.9343098e-07 Loss: 1.9071180545893185e-07\n",
      "Gradient: 6.99517e-07 Loss: 1.8185637102874351e-07\n",
      "Gradient: 7.5149256e-07 Loss: 1.9224452690499069e-07\n",
      "Gradient: 1.3079598e-06 Loss: 1.6086421202506548e-07\n",
      "Gradient: 3.473757e-07 Loss: 1.669836069121781e-07\n",
      "Gradient: 3.560068e-07 Loss: 1.533937691533538e-07\n",
      "Gradient: 1.9719653e-06 Loss: 1.847853946893944e-07\n",
      "Gradient: 2.2102242e-06 Loss: 1.8931541963714457e-07\n",
      "Gradient: 1.8432041e-07 Loss: 2.0241695869079498e-07\n",
      "Gradient: 1.5791402e-06 Loss: 1.706733911532865e-07\n",
      "Gradient: 1.935709e-06 Loss: 1.9062103717715217e-07\n",
      "Gradient: 1.0449061e-06 Loss: 1.8060755593296563e-07\n",
      "Gradient: 7.989578e-07 Loss: 1.8034631755388848e-07\n",
      "Gradient: 4.9727794e-07 Loss: 1.701056982975994e-07\n",
      "Gradient: 2.719716e-06 Loss: 1.9633174351459576e-07\n",
      "Gradient: 4.4527604e-07 Loss: 1.7786000654496094e-07\n",
      "Gradient: 7.240454e-07 Loss: 1.8278730043637855e-07\n",
      "Gradient: 6.7514975e-07 Loss: 1.8564831769651846e-07\n",
      "Gradient: 6.5592474e-07 Loss: 1.7258063801743145e-07\n",
      "Gradient: 4.923163e-07 Loss: 1.7766692863574463e-07\n",
      "Gradient: 2.5431083e-07 Loss: 1.7599810675505978e-07\n",
      "Gradient: 5.5707335e-07 Loss: 1.711956322481001e-07\n",
      "Gradient: 2.3068415e-06 Loss: 2.0280310243000106e-07\n",
      "Gradient: 9.091377e-07 Loss: 1.7186538888343725e-07\n",
      "Gradient: 7.097682e-07 Loss: 2.089904479400199e-07\n",
      "Gradient: 8.6837537e-07 Loss: 1.8709017529279967e-07\n",
      "Gradient: 1.0530671e-06 Loss: 1.7780321712734803e-07\n",
      "Gradient: 1.1501379e-06 Loss: 1.8769177311620904e-07\n",
      "Gradient: 9.327868e-08 Loss: 1.7642946848657932e-07\n",
      "Gradient: 4.6407416e-07 Loss: 1.9116592066363108e-07\n",
      "Gradient: 8.4514215e-07 Loss: 1.9316408431298744e-07\n",
      "Gradient: 9.837854e-07 Loss: 1.7813253923767056e-07\n",
      "Gradient: 4.5189267e-07 Loss: 1.7891580939751368e-07\n",
      "Gradient: 7.5216514e-07 Loss: 1.86386279447485e-07\n",
      "Gradient: 8.2357457e-07 Loss: 1.7742863202367214e-07\n",
      "Gradient: 1.5169654e-06 Loss: 1.7068473994186207e-07\n",
      "Gradient: 3.205418e-07 Loss: 1.9157467576746967e-07\n",
      "Gradient: 1.6047575e-06 Loss: 1.7925649468490215e-07\n",
      "Gradient: 1.6989068e-06 Loss: 1.8016471751517807e-07\n",
      "Gradient: 1.5164678e-06 Loss: 1.7127515026989688e-07\n",
      "Gradient: 6.2078277e-07 Loss: 1.491817405015657e-07\n",
      "Gradient: 1.0966966e-06 Loss: 1.5866172423291876e-07\n",
      "Gradient: 1.312274e-06 Loss: 1.9433348275773217e-07\n",
      "Gradient: 1.3098555e-06 Loss: 2.0011233559102948e-07\n",
      "Gradient: 6.778848e-07 Loss: 1.5800323325265708e-07\n",
      "Gradient: 6.5175084e-07 Loss: 1.6610943186871434e-07\n",
      "Gradient: 7.506569e-07 Loss: 1.8869102902385748e-07\n",
      "Gradient: 2.550555e-07 Loss: 1.89962491958795e-07\n",
      "Gradient: 1.8386447e-06 Loss: 1.773491476342315e-07\n",
      "Gradient: 4.0681658e-07 Loss: 1.5465402138185407e-07\n",
      "Gradient: 1.027305e-06 Loss: 2.0760547769782534e-07\n",
      "Gradient: 2.1095175e-06 Loss: 1.994990986039132e-07\n",
      "Gradient: 3.852918e-07 Loss: 2.0341616320251886e-07\n",
      "Gradient: 4.9485493e-07 Loss: 1.6981059616227868e-07\n",
      "Gradient: 1.1392367e-06 Loss: 1.8639768910588829e-07\n",
      "Gradient: 2.3732798e-07 Loss: 1.7568012230147664e-07\n",
      "Gradient: 4.4765088e-07 Loss: 2.016108043771207e-07\n",
      "Gradient: 2.237456e-06 Loss: 2.2189905971951399e-07\n",
      "Gradient: 2.018612e-06 Loss: 1.7701988639373666e-07\n",
      "Gradient: 8.9419336e-07 Loss: 1.9303932674574753e-07\n",
      "Gradient: 2.5258046e-07 Loss: 1.6870934504235417e-07\n",
      "Gradient: 7.863921e-07 Loss: 1.605008844052236e-07\n",
      "Gradient: 1.4541874e-06 Loss: 1.7508985621361718e-07\n",
      "Gradient: 4.1011512e-07 Loss: 1.8280994590706238e-07\n",
      "Gradient: 1.0155683e-06 Loss: 1.9852290430814416e-07\n",
      "Gradient: 6.768695e-07 Loss: 1.6898181390464136e-07\n",
      "Gradient: 1.1784549e-06 Loss: 1.8248068253493936e-07\n",
      "Gradient: 3.852146e-07 Loss: 1.6247641004459487e-07\n",
      "Gradient: 5.8248963e-07 Loss: 1.7619113397889427e-07\n",
      "Gradient: 6.1458854e-07 Loss: 1.6713118261198664e-07\n",
      "Gradient: 1.1725567e-07 Loss: 1.539046809106992e-07\n",
      "Gradient: 1.3889297e-06 Loss: 1.9873853815965958e-07\n",
      "Gradient: 5.067946e-07 Loss: 1.9677443863959827e-07\n",
      "Gradient: 1.4279234e-06 Loss: 2.070719086570231e-07\n",
      "Gradient: 1.3513624e-06 Loss: 1.6931107632937407e-07\n",
      "Gradient: 7.844162e-07 Loss: 1.9302794669329159e-07\n",
      "Gradient: 3.8339135e-07 Loss: 1.8712419110518871e-07\n",
      "Gradient: 4.10365e-07 Loss: 1.6446312921895394e-07\n",
      "Gradient: 1.2600026e-06 Loss: 1.7351173037620052e-07\n",
      "Gradient: 2.03423e-06 Loss: 1.7168382745088215e-07\n",
      "Gradient: 7.2188004e-07 Loss: 2.0433570616281334e-07\n",
      "Gradient: 1.1946227e-06 Loss: 1.8224240297589252e-07\n",
      "Gradient: 1.7543954e-06 Loss: 2.1042110773805688e-07\n",
      "Gradient: 6.464621e-07 Loss: 1.723422821934643e-07\n",
      "Gradient: 3.4257224e-07 Loss: 1.8896342387127638e-07\n",
      "Gradient: 1.014542e-06 Loss: 1.7974468183486654e-07\n",
      "Gradient: 1.0788619e-06 Loss: 1.588205928252743e-07\n",
      "Gradient: 6.833666e-07 Loss: 1.9307325658246554e-07\n",
      "Gradient: 1.5471336e-06 Loss: 2.0305281083210503e-07\n",
      "Gradient: 1.913486e-06 Loss: 1.829462031347854e-07\n",
      "Gradient: 3.559839e-07 Loss: 1.5410900952398758e-07\n",
      "Gradient: 8.622221e-07 Loss: 1.6691543625787137e-07\n",
      "Gradient: 7.5457365e-07 Loss: 1.7454489219896157e-07\n",
      "Gradient: 1.9762615e-06 Loss: 1.7896123907235051e-07\n",
      "Gradient: 3.8217303e-07 Loss: 1.6861851162749038e-07\n",
      "Gradient: 9.709571e-07 Loss: 1.7910892514313066e-07\n",
      "Gradient: 4.6173378e-07 Loss: 1.644859357459912e-07\n",
      "Gradient: 1.3355225e-06 Loss: 1.8086855249066503e-07\n",
      "Gradient: 1.28578e-06 Loss: 2.0897924031260117e-07\n",
      "Gradient: 1.3307656e-06 Loss: 1.8421783281041827e-07\n",
      "Gradient: 2.0577188e-06 Loss: 2.0548244326808646e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: 3.404075e-07 Loss: 1.802214789847767e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise max val: tensor(0.1255, device='cuda:5', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#Trigger generating stage\n",
    "for param in poi_warm_up_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "batch_pert = torch.autograd.Variable(noise.cuda(), requires_grad=True)\n",
    "batch_opt = torch.optim.RAdam(params=[batch_pert],lr=generating_lr_tri)\n",
    "for minmin in tqdm.notebook.tqdm(range(gen_round)):\n",
    "    loss_list = []\n",
    "    for images, labels in trigger_gen_loaders:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        new_images = torch.clone(images)\n",
    "        clamp_batch_pert = torch.clamp(batch_pert,-l_inf_r*2,l_inf_r*2)\n",
    "        new_images = torch.clamp(apply_noise_patch(clamp_batch_pert,new_images.clone(),mode=patch_mode),-1,1)\n",
    "        per_logits = poi_warm_up_model.forward(new_images)\n",
    "        loss = criterion(per_logits, labels)\n",
    "\n",
    "        loss_regu = torch.mean(loss)\n",
    "        batch_opt.zero_grad()\n",
    "        loss_list.append(float(loss_regu.data))\n",
    "        loss_regu.backward(retain_graph = True)\n",
    "        batch_opt.step()\n",
    "    ave_loss = np.average(np.array(loss_list))\n",
    "    ave_grad = np.sum(abs(batch_pert.grad).detach().cpu().numpy())\n",
    "    print('Gradient:',ave_grad,'Loss:', ave_loss)\n",
    "    if ave_grad == 0:\n",
    "        break\n",
    "\n",
    "noise = torch.clamp(batch_pert,-l_inf_r*2,l_inf_r*2)\n",
    "best_noise = noise.clone().detach().cpu()\n",
    "plt.imshow(np.transpose(noise[0].detach().cpu(),(1,2,0)))\n",
    "plt.show()\n",
    "print('Noise max val:',noise.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69959a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the trigger\n",
    "import time\n",
    "save_name = './checkpoint/best_noise'+'_'+ time.strftime(\"%m-%d-%H_%M_%S\",time.localtime(time.time())) \n",
    "np.save(save_name, best_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fea60aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Poisoning amount use for the target class\n",
    "poison_amount = 1000\n",
    "\n",
    "#Model uses for testing\n",
    "noise_testing_model = ResNet18().cuda()    \n",
    "\n",
    "#Training parameters\n",
    "training_epochs = 200\n",
    "training_lr = 0.1\n",
    "test_batch_size = 150\n",
    "\n",
    "#The multiple of noise amplification during testing\n",
    "multi_test = 3\n",
    "\n",
    "#random seed for testing stage\n",
    "random_seed = 65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7c3a942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision.models as models\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "# model = noise_testing_model\n",
    "model=ResNet18().cuda()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=training_lr, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=training_epochs)\n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "transform_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "poi_ori_train = torchvision.datasets.CIFAR10(root=root, train=True, download=True, transform=transform_tensor)\n",
    "poi_ori_test = torchvision.datasets.CIFAR10(root=root, train=False, download=True, transform=transform_tensor)\n",
    "transform_after_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fb02649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing dataset size is: 50000  Poison numbers is: 1000\n"
     ]
    }
   ],
   "source": [
    "#Poison traing\n",
    "random_poison_idx = random.sample(train_target_list, poison_amount)\n",
    "poison_train_target = poison_image(poi_ori_train,random_poison_idx,best_noise.cpu(),transform_after_train)\n",
    "print('Traing dataset size is:',len(poison_train_target),\" Poison numbers is:\",len(random_poison_idx))\n",
    "clean_train_loader = DataLoader(poison_train_target, batch_size=test_batch_size, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "abed8283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33677,\n",
       " 23343,\n",
       " 23222,\n",
       " 41763,\n",
       " 17561,\n",
       " 35887,\n",
       " 36921,\n",
       " 42993,\n",
       " 35862,\n",
       " 44909,\n",
       " 27549,\n",
       " 35405,\n",
       " 17980,\n",
       " 5715,\n",
       " 45785,\n",
       " 37647,\n",
       " 21284,\n",
       " 15696,\n",
       " 38129,\n",
       " 3476,\n",
       " 20671,\n",
       " 9053,\n",
       " 12782,\n",
       " 42986,\n",
       " 10968,\n",
       " 9917,\n",
       " 11099,\n",
       " 28593,\n",
       " 30021,\n",
       " 47123,\n",
       " 29943,\n",
       " 18376,\n",
       " 18162,\n",
       " 32330,\n",
       " 36316,\n",
       " 38451,\n",
       " 3845,\n",
       " 12361,\n",
       " 1745,\n",
       " 27186,\n",
       " 20061,\n",
       " 25984,\n",
       " 21836,\n",
       " 737,\n",
       " 13777,\n",
       " 34930,\n",
       " 5836,\n",
       " 21018,\n",
       " 44584,\n",
       " 803,\n",
       " 14569,\n",
       " 13059,\n",
       " 46766,\n",
       " 43747,\n",
       " 35146,\n",
       " 10616,\n",
       " 41894,\n",
       " 34062,\n",
       " 26215,\n",
       " 17834,\n",
       " 19070,\n",
       " 24195,\n",
       " 45303,\n",
       " 28948,\n",
       " 15563,\n",
       " 30251,\n",
       " 47127,\n",
       " 49053,\n",
       " 533,\n",
       " 24789,\n",
       " 5166,\n",
       " 21591,\n",
       " 23346,\n",
       " 36510,\n",
       " 13042,\n",
       " 10624,\n",
       " 10725,\n",
       " 7303,\n",
       " 22397,\n",
       " 35031,\n",
       " 48391,\n",
       " 32181,\n",
       " 30454,\n",
       " 44491,\n",
       " 6414,\n",
       " 46478,\n",
       " 33121,\n",
       " 12200,\n",
       " 13130,\n",
       " 39854,\n",
       " 39324,\n",
       " 23692,\n",
       " 38535,\n",
       " 26855,\n",
       " 40960,\n",
       " 25174,\n",
       " 12058,\n",
       " 48522,\n",
       " 38365,\n",
       " 45795,\n",
       " 1670,\n",
       " 7308,\n",
       " 14399,\n",
       " 42158,\n",
       " 28107,\n",
       " 43745,\n",
       " 2537,\n",
       " 14013,\n",
       " 21392,\n",
       " 17016,\n",
       " 21412,\n",
       " 23677,\n",
       " 19236,\n",
       " 25366,\n",
       " 32059,\n",
       " 12506,\n",
       " 33890,\n",
       " 11187,\n",
       " 40704,\n",
       " 22618,\n",
       " 7380,\n",
       " 45990,\n",
       " 49683,\n",
       " 43365,\n",
       " 38244,\n",
       " 21860,\n",
       " 17690,\n",
       " 17487,\n",
       " 18143,\n",
       " 42803,\n",
       " 31375,\n",
       " 20589,\n",
       " 12978,\n",
       " 17735,\n",
       " 27555,\n",
       " 779,\n",
       " 24074,\n",
       " 29374,\n",
       " 22708,\n",
       " 13071,\n",
       " 31741,\n",
       " 32308,\n",
       " 43441,\n",
       " 7713,\n",
       " 21491,\n",
       " 5992,\n",
       " 22279,\n",
       " 46450,\n",
       " 43569,\n",
       " 46837,\n",
       " 34023,\n",
       " 808,\n",
       " 48082,\n",
       " 22032,\n",
       " 44938,\n",
       " 30475,\n",
       " 47948,\n",
       " 16319,\n",
       " 4431,\n",
       " 21900,\n",
       " 3274,\n",
       " 40217,\n",
       " 12847,\n",
       " 34614,\n",
       " 38741,\n",
       " 29814,\n",
       " 42428,\n",
       " 39580,\n",
       " 47180,\n",
       " 17329,\n",
       " 10428,\n",
       " 8888,\n",
       " 11433,\n",
       " 40372,\n",
       " 29707,\n",
       " 11705,\n",
       " 43177,\n",
       " 39747,\n",
       " 38905,\n",
       " 14327,\n",
       " 4012,\n",
       " 20317,\n",
       " 19874,\n",
       " 35723,\n",
       " 19985,\n",
       " 44905,\n",
       " 7275,\n",
       " 7410,\n",
       " 9313,\n",
       " 4014,\n",
       " 16030,\n",
       " 21577,\n",
       " 46106,\n",
       " 24115,\n",
       " 4482,\n",
       " 13035,\n",
       " 6210,\n",
       " 46562,\n",
       " 3331,\n",
       " 13682,\n",
       " 2641,\n",
       " 3245,\n",
       " 4976,\n",
       " 26873,\n",
       " 33361,\n",
       " 23919,\n",
       " 11455,\n",
       " 47142,\n",
       " 2007,\n",
       " 36261,\n",
       " 16790,\n",
       " 43122,\n",
       " 44327,\n",
       " 42234,\n",
       " 18588,\n",
       " 9272,\n",
       " 34115,\n",
       " 34669,\n",
       " 49558,\n",
       " 37947,\n",
       " 20957,\n",
       " 8092,\n",
       " 8234,\n",
       " 8874,\n",
       " 21650,\n",
       " 47742,\n",
       " 46784,\n",
       " 9297,\n",
       " 4830,\n",
       " 21765,\n",
       " 35259,\n",
       " 23159,\n",
       " 1844,\n",
       " 24670,\n",
       " 31045,\n",
       " 41312,\n",
       " 45738,\n",
       " 23588,\n",
       " 6,\n",
       " 9858,\n",
       " 28770,\n",
       " 45558,\n",
       " 47255,\n",
       " 9503,\n",
       " 37745,\n",
       " 6133,\n",
       " 35460,\n",
       " 16833,\n",
       " 45360,\n",
       " 45252,\n",
       " 6359,\n",
       " 30102,\n",
       " 45414,\n",
       " 20318,\n",
       " 39683,\n",
       " 24061,\n",
       " 35677,\n",
       " 4896,\n",
       " 28944,\n",
       " 2080,\n",
       " 43127,\n",
       " 4455,\n",
       " 45060,\n",
       " 13655,\n",
       " 12362,\n",
       " 5215,\n",
       " 16742,\n",
       " 15717,\n",
       " 31802,\n",
       " 19223,\n",
       " 17373,\n",
       " 12504,\n",
       " 22228,\n",
       " 47872,\n",
       " 20908,\n",
       " 3037,\n",
       " 35486,\n",
       " 27800,\n",
       " 36344,\n",
       " 21663,\n",
       " 15443,\n",
       " 27592,\n",
       " 35833,\n",
       " 14078,\n",
       " 35837,\n",
       " 23288,\n",
       " 9001,\n",
       " 7336,\n",
       " 28345,\n",
       " 32916,\n",
       " 36300,\n",
       " 34079,\n",
       " 32943,\n",
       " 2744,\n",
       " 25379,\n",
       " 43478,\n",
       " 27729,\n",
       " 1497,\n",
       " 3193,\n",
       " 33135,\n",
       " 13989,\n",
       " 30402,\n",
       " 358,\n",
       " 23062,\n",
       " 12166,\n",
       " 10628,\n",
       " 17769,\n",
       " 39407,\n",
       " 48922,\n",
       " 2372,\n",
       " 14761,\n",
       " 31007,\n",
       " 47565,\n",
       " 10802,\n",
       " 23950,\n",
       " 13485,\n",
       " 10160,\n",
       " 20189,\n",
       " 7942,\n",
       " 48833,\n",
       " 6026,\n",
       " 19899,\n",
       " 2378,\n",
       " 8682,\n",
       " 46365,\n",
       " 11084,\n",
       " 31020,\n",
       " 28173,\n",
       " 29033,\n",
       " 43450,\n",
       " 36727,\n",
       " 2927,\n",
       " 38746,\n",
       " 3769,\n",
       " 3205,\n",
       " 36130,\n",
       " 38038,\n",
       " 16111,\n",
       " 46877,\n",
       " 36759,\n",
       " 31275,\n",
       " 5299,\n",
       " 27326,\n",
       " 39728,\n",
       " 29637,\n",
       " 22515,\n",
       " 2217,\n",
       " 5226,\n",
       " 40661,\n",
       " 36585,\n",
       " 2902,\n",
       " 25095,\n",
       " 44340,\n",
       " 39786,\n",
       " 15813,\n",
       " 36305,\n",
       " 5634,\n",
       " 25125,\n",
       " 33699,\n",
       " 7878,\n",
       " 35967,\n",
       " 36340,\n",
       " 27823,\n",
       " 20426,\n",
       " 20038,\n",
       " 31002,\n",
       " 35387,\n",
       " 43570,\n",
       " 11813,\n",
       " 11123,\n",
       " 32127,\n",
       " 32513,\n",
       " 28114,\n",
       " 39983,\n",
       " 22977,\n",
       " 35216,\n",
       " 33776,\n",
       " 29989,\n",
       " 12421,\n",
       " 30531,\n",
       " 48,\n",
       " 36170,\n",
       " 24533,\n",
       " 11193,\n",
       " 12667,\n",
       " 33021,\n",
       " 3338,\n",
       " 23775,\n",
       " 4633,\n",
       " 15584,\n",
       " 13506,\n",
       " 22835,\n",
       " 9520,\n",
       " 49156,\n",
       " 21139,\n",
       " 34513,\n",
       " 25034,\n",
       " 4008,\n",
       " 30778,\n",
       " 44495,\n",
       " 22810,\n",
       " 5758,\n",
       " 6621,\n",
       " 29870,\n",
       " 6616,\n",
       " 35673,\n",
       " 49450,\n",
       " 48531,\n",
       " 787,\n",
       " 49573,\n",
       " 40911,\n",
       " 15639,\n",
       " 43190,\n",
       " 35360,\n",
       " 4525,\n",
       " 1614,\n",
       " 20285,\n",
       " 44797,\n",
       " 28452,\n",
       " 38765,\n",
       " 41085,\n",
       " 21442,\n",
       " 41512,\n",
       " 39960,\n",
       " 19287,\n",
       " 32299,\n",
       " 14308,\n",
       " 46541,\n",
       " 36849,\n",
       " 7165,\n",
       " 26990,\n",
       " 2177,\n",
       " 19343,\n",
       " 41299,\n",
       " 40961,\n",
       " 13081,\n",
       " 15398,\n",
       " 4471,\n",
       " 23453,\n",
       " 32972,\n",
       " 46589,\n",
       " 37009,\n",
       " 20102,\n",
       " 19157,\n",
       " 27416,\n",
       " 37121,\n",
       " 26976,\n",
       " 6230,\n",
       " 20633,\n",
       " 9002,\n",
       " 49730,\n",
       " 4113,\n",
       " 43285,\n",
       " 4880,\n",
       " 13794,\n",
       " 14195,\n",
       " 7844,\n",
       " 10756,\n",
       " 31333,\n",
       " 27393,\n",
       " 43300,\n",
       " 48344,\n",
       " 990,\n",
       " 30532,\n",
       " 18477,\n",
       " 31759,\n",
       " 42185,\n",
       " 48547,\n",
       " 8100,\n",
       " 48594,\n",
       " 37026,\n",
       " 17057,\n",
       " 46299,\n",
       " 46683,\n",
       " 32289,\n",
       " 47133,\n",
       " 18886,\n",
       " 11415,\n",
       " 8037,\n",
       " 6921,\n",
       " 12958,\n",
       " 18952,\n",
       " 17070,\n",
       " 38638,\n",
       " 29181,\n",
       " 39976,\n",
       " 46665,\n",
       " 14304,\n",
       " 15568,\n",
       " 19158,\n",
       " 13564,\n",
       " 7658,\n",
       " 32829,\n",
       " 24166,\n",
       " 5064,\n",
       " 16462,\n",
       " 14672,\n",
       " 24457,\n",
       " 34088,\n",
       " 38546,\n",
       " 29728,\n",
       " 38883,\n",
       " 1576,\n",
       " 40177,\n",
       " 2869,\n",
       " 12724,\n",
       " 12191,\n",
       " 10406,\n",
       " 11650,\n",
       " 45367,\n",
       " 6467,\n",
       " 42090,\n",
       " 15621,\n",
       " 9172,\n",
       " 31813,\n",
       " 9757,\n",
       " 49721,\n",
       " 43118,\n",
       " 30787,\n",
       " 33442,\n",
       " 18678,\n",
       " 48504,\n",
       " 22808,\n",
       " 36756,\n",
       " 26570,\n",
       " 4931,\n",
       " 46702,\n",
       " 21240,\n",
       " 15091,\n",
       " 11538,\n",
       " 8016,\n",
       " 21163,\n",
       " 14426,\n",
       " 14588,\n",
       " 35645,\n",
       " 16974,\n",
       " 1219,\n",
       " 47668,\n",
       " 33300,\n",
       " 10933,\n",
       " 3508,\n",
       " 20051,\n",
       " 15975,\n",
       " 7714,\n",
       " 45639,\n",
       " 36355,\n",
       " 8936,\n",
       " 20048,\n",
       " 22738,\n",
       " 8713,\n",
       " 43216,\n",
       " 19364,\n",
       " 18328,\n",
       " 7868,\n",
       " 18863,\n",
       " 10591,\n",
       " 6836,\n",
       " 30096,\n",
       " 34305,\n",
       " 2575,\n",
       " 5901,\n",
       " 33234,\n",
       " 14314,\n",
       " 46451,\n",
       " 1971,\n",
       " 44918,\n",
       " 13879,\n",
       " 47016,\n",
       " 4209,\n",
       " 26536,\n",
       " 7106,\n",
       " 47449,\n",
       " 31823,\n",
       " 18788,\n",
       " 7739,\n",
       " 11382,\n",
       " 3517,\n",
       " 43134,\n",
       " 6502,\n",
       " 2764,\n",
       " 4902,\n",
       " 9150,\n",
       " 11923,\n",
       " 33350,\n",
       " 22974,\n",
       " 40281,\n",
       " 28708,\n",
       " 40727,\n",
       " 28225,\n",
       " 34256,\n",
       " 27874,\n",
       " 4425,\n",
       " 5012,\n",
       " 21701,\n",
       " 47152,\n",
       " 24403,\n",
       " 11666,\n",
       " 6448,\n",
       " 27091,\n",
       " 21486,\n",
       " 28611,\n",
       " 46832,\n",
       " 27110,\n",
       " 8321,\n",
       " 12109,\n",
       " 42600,\n",
       " 7952,\n",
       " 7194,\n",
       " 40924,\n",
       " 27599,\n",
       " 36242,\n",
       " 40212,\n",
       " 4398,\n",
       " 31289,\n",
       " 20220,\n",
       " 14364,\n",
       " 45997,\n",
       " 2098,\n",
       " 16786,\n",
       " 25367,\n",
       " 46214,\n",
       " 20695,\n",
       " 47010,\n",
       " 23442,\n",
       " 6805,\n",
       " 48090,\n",
       " 38722,\n",
       " 33107,\n",
       " 40995,\n",
       " 16034,\n",
       " 14926,\n",
       " 48784,\n",
       " 11518,\n",
       " 33379,\n",
       " 28112,\n",
       " 16715,\n",
       " 45306,\n",
       " 14814,\n",
       " 38459,\n",
       " 31057,\n",
       " 9448,\n",
       " 12651,\n",
       " 19915,\n",
       " 33899,\n",
       " 17308,\n",
       " 32706,\n",
       " 6704,\n",
       " 40305,\n",
       " 40527,\n",
       " 28814,\n",
       " 42112,\n",
       " 24926,\n",
       " 48831,\n",
       " 29269,\n",
       " 3349,\n",
       " 26588,\n",
       " 42568,\n",
       " 1288,\n",
       " 22539,\n",
       " 35575,\n",
       " 6843,\n",
       " 8819,\n",
       " 10438,\n",
       " 1838,\n",
       " 22432,\n",
       " 14646,\n",
       " 35936,\n",
       " 16691,\n",
       " 44140,\n",
       " 35309,\n",
       " 11220,\n",
       " 19267,\n",
       " 32166,\n",
       " 6126,\n",
       " 29658,\n",
       " 46053,\n",
       " 24019,\n",
       " 47195,\n",
       " 44193,\n",
       " 2983,\n",
       " 37511,\n",
       " 14192,\n",
       " 696,\n",
       " 17134,\n",
       " 4888,\n",
       " 11137,\n",
       " 35362,\n",
       " 20149,\n",
       " 29948,\n",
       " 49969,\n",
       " 44512,\n",
       " 32470,\n",
       " 22248,\n",
       " 39646,\n",
       " 1936,\n",
       " 3692,\n",
       " 23586,\n",
       " 36675,\n",
       " 7974,\n",
       " 43527,\n",
       " 42581,\n",
       " 13542,\n",
       " 17339,\n",
       " 34086,\n",
       " 22275,\n",
       " 1139,\n",
       " 45193,\n",
       " 18496,\n",
       " 6685,\n",
       " 963,\n",
       " 2719,\n",
       " 41856,\n",
       " 38063,\n",
       " 31280,\n",
       " 22729,\n",
       " 19218,\n",
       " 31809,\n",
       " 5219,\n",
       " 6691,\n",
       " 6976,\n",
       " 44048,\n",
       " 42181,\n",
       " 9916,\n",
       " 15977,\n",
       " 30740,\n",
       " 4091,\n",
       " 20077,\n",
       " 24334,\n",
       " 8485,\n",
       " 42062,\n",
       " 23519,\n",
       " 3645,\n",
       " 46389,\n",
       " 7951,\n",
       " 44279,\n",
       " 33233,\n",
       " 7905,\n",
       " 44544,\n",
       " 16581,\n",
       " 11221,\n",
       " 12471,\n",
       " 35306,\n",
       " 48870,\n",
       " 3074,\n",
       " 48414,\n",
       " 3402,\n",
       " 11313,\n",
       " 1440,\n",
       " 48721,\n",
       " 32430,\n",
       " 7745,\n",
       " 42889,\n",
       " 21031,\n",
       " 12287,\n",
       " 47450,\n",
       " 2704,\n",
       " 24885,\n",
       " 45660,\n",
       " 9249,\n",
       " 23070,\n",
       " 1693,\n",
       " 42615,\n",
       " 46291,\n",
       " 28343,\n",
       " 1107,\n",
       " 23452,\n",
       " 13250,\n",
       " 8865,\n",
       " 5252,\n",
       " 17955,\n",
       " 22441,\n",
       " 34377,\n",
       " 27046,\n",
       " 24935,\n",
       " 26299,\n",
       " 7783,\n",
       " 24710,\n",
       " 30145,\n",
       " 24623,\n",
       " 2507,\n",
       " 19463,\n",
       " 38520,\n",
       " 23102,\n",
       " 13033,\n",
       " 48014,\n",
       " 5824,\n",
       " 5296,\n",
       " 5016,\n",
       " 21057,\n",
       " 28872,\n",
       " 23217,\n",
       " 2237,\n",
       " 2816,\n",
       " 3416,\n",
       " 21973,\n",
       " 46261,\n",
       " 11354,\n",
       " 49972,\n",
       " 37934,\n",
       " 34654,\n",
       " 3848,\n",
       " 44351,\n",
       " 14500,\n",
       " 25446,\n",
       " 48270,\n",
       " 17379,\n",
       " 29531,\n",
       " 25847,\n",
       " 9876,\n",
       " 43106,\n",
       " 47492,\n",
       " 8195,\n",
       " 46983,\n",
       " 42020,\n",
       " 37368,\n",
       " 3662,\n",
       " 30731,\n",
       " 43593,\n",
       " 30524,\n",
       " 21040,\n",
       " 38054,\n",
       " 39310,\n",
       " 49686,\n",
       " 6390,\n",
       " 19655,\n",
       " 4052,\n",
       " 20724,\n",
       " 1458,\n",
       " 2163,\n",
       " 2860,\n",
       " 38560,\n",
       " 13970,\n",
       " 39248,\n",
       " 196,\n",
       " 30067,\n",
       " 11340,\n",
       " 9603,\n",
       " 7653,\n",
       " 30855,\n",
       " 30405,\n",
       " 41644,\n",
       " 27484,\n",
       " 1285,\n",
       " 43314,\n",
       " 28834,\n",
       " 5647,\n",
       " 39515,\n",
       " 25427,\n",
       " 701,\n",
       " 46014,\n",
       " 24904,\n",
       " 40256,\n",
       " 11961,\n",
       " 36367,\n",
       " 560,\n",
       " 30493,\n",
       " 32499,\n",
       " 383,\n",
       " 13671,\n",
       " 29885,\n",
       " 21656,\n",
       " 29403,\n",
       " 16266,\n",
       " 37941,\n",
       " 3944,\n",
       " 29779,\n",
       " 37766,\n",
       " 43523,\n",
       " 17538,\n",
       " 39309,\n",
       " 32153,\n",
       " 33032,\n",
       " 15310,\n",
       " 522,\n",
       " 45940,\n",
       " 45967,\n",
       " 31419,\n",
       " 3771,\n",
       " 31063,\n",
       " 21526,\n",
       " 37663,\n",
       " 12455,\n",
       " 27884,\n",
       " 18756,\n",
       " 8454,\n",
       " 42144,\n",
       " 16712,\n",
       " 26663,\n",
       " 18727,\n",
       " 47904,\n",
       " 26956,\n",
       " 12790,\n",
       " 24,\n",
       " 1800,\n",
       " 11295,\n",
       " 33508,\n",
       " 5537,\n",
       " 26541,\n",
       " 37243,\n",
       " 20673,\n",
       " 25217,\n",
       " 3520,\n",
       " 39935,\n",
       " 13831,\n",
       " 33708,\n",
       " 26058,\n",
       " 8169,\n",
       " 827,\n",
       " 24771,\n",
       " 25455,\n",
       " 4356,\n",
       " 38170,\n",
       " 43010,\n",
       " 2938,\n",
       " 48101,\n",
       " 11884,\n",
       " 48323,\n",
       " 39847,\n",
       " 40385,\n",
       " 778,\n",
       " 26760,\n",
       " 4853,\n",
       " 5609,\n",
       " 31005,\n",
       " 22448,\n",
       " 40333,\n",
       " 48388,\n",
       " 35718,\n",
       " 3428,\n",
       " 16980,\n",
       " 19224,\n",
       " 29925,\n",
       " 2966,\n",
       " 21513,\n",
       " 2789,\n",
       " 11197,\n",
       " 46563,\n",
       " 45855,\n",
       " 13047,\n",
       " 3299,\n",
       " 16093,\n",
       " 39610,\n",
       " 10651,\n",
       " 13727,\n",
       " 463,\n",
       " 6069,\n",
       " 1024,\n",
       " 6327,\n",
       " 1430,\n",
       " 34747,\n",
       " 38046,\n",
       " 20065,\n",
       " 34320,\n",
       " 22495,\n",
       " 36581,\n",
       " 21145,\n",
       " 5417,\n",
       " 9712,\n",
       " 17185,\n",
       " 32678,\n",
       " 42542,\n",
       " 11012,\n",
       " 1180,\n",
       " 2093,\n",
       " 5527,\n",
       " 49888,\n",
       " 6801,\n",
       " 13431,\n",
       " 7279,\n",
       " 21746,\n",
       " 27399,\n",
       " 42147,\n",
       " 21504,\n",
       " 6628,\n",
       " 43503,\n",
       " 559,\n",
       " 42594,\n",
       " 13341,\n",
       " 2875,\n",
       " 32741,\n",
       " 31941,\n",
       " 12616,\n",
       " 36972,\n",
       " 40020,\n",
       " 26146,\n",
       " 1995,\n",
       " 8055,\n",
       " 47392,\n",
       " 24033,\n",
       " 6757,\n",
       " 21135,\n",
       " 42848,\n",
       " 47594,\n",
       " 49458,\n",
       " 3791,\n",
       " 7850,\n",
       " 24461,\n",
       " 49700,\n",
       " 20029,\n",
       " 1438]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_poison_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "412da7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f211849b588>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(poi_ori_train[808][0],(1,2,0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e69ce393",
   "metadata": {},
   "source": [
    "### Plot the image to see if trigger is visible \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46359991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate model if you chose to use\n",
    "# class SmallCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SmallCNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#         self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x, last=False):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 16 * 5 * 5)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         output = self.fc3(x)\n",
    "        \n",
    "#         if last:\n",
    "#             return output, x\n",
    "#         else:\n",
    "#             return output\n",
    "\n",
    "# #     def getFeature(self, x, numpy=True):\n",
    "# #         if x.shape[1]==32:\n",
    "# #           x = np.moveaxis(x, 3, 1)\n",
    "# #         x = torch.Tensor(x).cuda()\n",
    "# #         x = self.pool(F.relu(self.conv1(x)))\n",
    "# #         x = self.pool(F.relu(self.conv2(x)))\n",
    "# #         x = torch.flatten(x, 1)\n",
    "# #         if numpy:\n",
    "# #           return x.detach().cpu().numpy()\n",
    "# #         else:\n",
    "# #           return x\n",
    "\n",
    "# #     def get_embedding_dim(self):\n",
    "# #         return 84\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7012d5",
   "metadata": {},
   "source": [
    "## Eval Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61898ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.models import resnet18\n",
    "# model=noise_testing_model\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "\n",
    "# Convert batchnorm modules to Group Norm modules for DP-SGD\n",
    "from opacus.utils.module_modification import convert_batchnorm_modules\n",
    "\n",
    "\n",
    "model = convert_batchnorm_modules(model) #comment out if not implementing DP-SGD \n",
    "model=model.to(device)\n",
    "# Note that we are using the backbone as a black-box featurizer. It's never trained, so we can keep BatchNorms in there.\n",
    "# model=SmallCNN().cuda()\n",
    "\n",
    "# The optimizer needs to point to the new model\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=0.1 ,\n",
    "                      momentum=0.9, weight_decay=5e-4, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c798d6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshugj/miniconda3/envs/project1/lib/python3.7/site-packages/opacus/privacy_engine.py:753: UserWarning: The sample rate will be defined from ``batch_size`` and ``sample_size``.The returned privacy budget will be incorrect.\n",
      "  \"The sample rate will be defined from ``batch_size`` and ``sample_size``.\"\n",
      "/home/himanshugj/miniconda3/envs/project1/lib/python3.7/site-packages/opacus/privacy_engine.py:237: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_rng`` turned on.\n",
      "  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"
     ]
    }
   ],
   "source": [
    "#Comment out cell if not implementing DP-SGD\n",
    "privacy_engine=opacus.PrivacyEngine(model,\n",
    "                                   batch_size=64,\n",
    "                                   sample_size=50000,\n",
    "                                   alphas=range(2,32),\n",
    "                                   noise_multiplier=0.01,\n",
    "                                   \n",
    "                                   max_grad_norm=8.0)\n",
    "privacy_engine.attach(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a78c78b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poison test dataset size is: 9000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Attack success rate testing\n",
    "test_non_target = list(np.where(np.array(test_label)!=lab)[0])\n",
    "test_non_target_change_image_label = poison_image_label(poi_ori_test,test_non_target,best_noise.cpu()*multi_test,lab,None)\n",
    "asr_loaders = torch.utils.data.DataLoader(test_non_target_change_image_label, batch_size=test_batch_size, shuffle=True, num_workers=2)\n",
    "print('Poison test dataset size is:',len(test_non_target_change_image_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e42b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean acc test dataset\n",
    "clean_test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c3c03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target clean test dataset\n",
    "test_target = list(np.where(np.array(test_label)==lab)[0])\n",
    "target_test_set = Subset(testset,test_target)\n",
    "target_test_loader = torch.utils.data.DataLoader(target_test_set, batch_size=test_batch_size, shuffle=True, num_workers=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37a61a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from util import AverageMeter\n",
    "train_ACC = []\n",
    "test_ACC = []\n",
    "clean_ACC = []\n",
    "target_ACC = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a82c4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599fbfda2bc741f59dd5c11c3df150c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc1fb1a521044bea1197fb4bcbded61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/himanshugj/miniconda3/envs/project1/lib/python3.7/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attack success rate 5.52\n",
      "Test_loss: tensor(3.1275, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 44.26\n",
      "Test_loss: tensor(1.8434, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 26.00\n",
      "Test_loss: tensor(3.0416, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f092b78ed492785ab947365e7fce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.3976, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 72.26\n",
      "Test_loss: tensor(0.8954, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 44.36\n",
      "Test_loss: tensor(1.9970, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 23.00\n",
      "Test_loss: tensor(2.5275, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4f0ef4d8814057a519d63b98a2feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8031, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 75.78\n",
      "Test_loss: tensor(0.8585, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 61.83\n",
      "Test_loss: tensor(1.1586, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 50.80\n",
      "Test_loss: tensor(1.4697, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f94566e1bd41148b9a76712f8374f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7526, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 95.88\n",
      "Test_loss: tensor(0.2082, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.88\n",
      "Test_loss: tensor(0.9358, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 67.30\n",
      "Test_loss: tensor(1.3167, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe0ff5320664bde9908f9211444ab71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.2315, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 85.78\n",
      "Test_loss: tensor(0.6433, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 58.97\n",
      "Test_loss: tensor(1.8816, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 30.70\n",
      "Test_loss: tensor(3.0592, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbb026e44bb4bc7be6bed874429e4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5395, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 96.13\n",
      "Test_loss: tensor(0.2793, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.35\n",
      "Test_loss: tensor(1.1088, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 67.40\n",
      "Test_loss: tensor(1.3000, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfb40904d5f4661a834ddf3596ca1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6965, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 96.61\n",
      "Test_loss: tensor(0.2073, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 70.52\n",
      "Test_loss: tensor(1.1519, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 49.70\n",
      "Test_loss: tensor(1.6776, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b92f81f0b74bf7a116610dde6f5305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6583, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 86.00\n",
      "Test_loss: tensor(0.5523, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 68.29\n",
      "Test_loss: tensor(1.1499, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 41.10\n",
      "Test_loss: tensor(1.8792, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e35d5a3a734c00accfbef93589d200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9138, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.49\n",
      "Test_loss: tensor(0.0180, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.31\n",
      "Test_loss: tensor(0.7784, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 50.80\n",
      "Test_loss: tensor(2.2284, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823ba50d6c4c42a694f5eb8cdabf67ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5433, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 58.20\n",
      "Test_loss: tensor(1.8218, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 63.08\n",
      "Test_loss: tensor(1.9367, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 34.50\n",
      "Test_loss: tensor(3.0344, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7415a99f5f3b47d197c655fbb39445b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.0531, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.81\n",
      "Test_loss: tensor(0.0585, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 63.09\n",
      "Test_loss: tensor(1.5771, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 66.20\n",
      "Test_loss: tensor(1.7509, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86d06aebd15469ab7a506e9ac64e7f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7757, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.93\n",
      "Test_loss: tensor(0.0019, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.20\n",
      "Test_loss: tensor(1.2864, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 57.30\n",
      "Test_loss: tensor(1.7130, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f25e85e6c37478e81665e301c800742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6188, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 94.99\n",
      "Test_loss: tensor(0.1695, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 68.62\n",
      "Test_loss: tensor(1.5320, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 32.70\n",
      "Test_loss: tensor(3.3861, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c9123e967b4dc8975adc231c7c5fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5071, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.57\n",
      "Test_loss: tensor(0.0644, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.06\n",
      "Test_loss: tensor(1.0934, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 45.10\n",
      "Test_loss: tensor(2.5505, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0779928131427e8628d81d6dbf1914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.3528, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.96\n",
      "Test_loss: tensor(0.0017, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 65.98\n",
      "Test_loss: tensor(1.5793, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 54.90\n",
      "Test_loss: tensor(2.2389, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf582e99175d4d70b24024f54203eaab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.3701, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.92\n",
      "Test_loss: tensor(0.0022, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 69.27\n",
      "Test_loss: tensor(1.3804, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 63.20\n",
      "Test_loss: tensor(1.2987, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f0908244784b89914e107523f4fa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9690, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.93\n",
      "Test_loss: tensor(0.0015, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 67.50\n",
      "Test_loss: tensor(1.3551, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 47.50\n",
      "Test_loss: tensor(2.9741, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598b17512fc84486bbb535772cba36bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.0251, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.84\n",
      "Test_loss: tensor(0.0018, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 70.74\n",
      "Test_loss: tensor(1.3556, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.40\n",
      "Test_loss: tensor(1.3784, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3692eb53f27b412a8ab09bc6114b525b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9733, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.97\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.74\n",
      "Test_loss: tensor(1.0104, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 64.60\n",
      "Test_loss: tensor(1.5672, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a26d6b92a94df283e955bde16d6676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5055, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.96\n",
      "Test_loss: tensor(0.0019, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.23\n",
      "Test_loss: tensor(1.0673, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 43.60\n",
      "Test_loss: tensor(2.9993, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb929f0e3af465a8b61b3a204b9c283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1812, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.51\n",
      "Test_loss: tensor(0.8426, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 80.20\n",
      "Test_loss: tensor(0.8530, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3353a289b2b444c99ad63e719cc8d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6640, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0016, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 63.01\n",
      "Test_loss: tensor(1.4954, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 39.40\n",
      "Test_loss: tensor(2.8309, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a234d3817c94aebb5efce21f03e7039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1293, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.89\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 68.64\n",
      "Test_loss: tensor(1.4575, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 31.40\n",
      "Test_loss: tensor(2.6047, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41045d6fd78743fa8d99342299ec0af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attack success rate 90.70\n",
      "Test_loss: tensor(0.1978, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.39\n",
      "Test_loss: tensor(1.0932, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 40.00\n",
      "Test_loss: tensor(2.7500, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72942ed44810407e966c502d06a64dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9562, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 69.40\n",
      "Test_loss: tensor(1.4433, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 46.10\n",
      "Test_loss: tensor(2.8268, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e951650596e4109a16c99ff38ef988a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9842, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 61.15\n",
      "Test_loss: tensor(1.7741, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 68.60\n",
      "Test_loss: tensor(1.5414, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e15b333af74caea5dbd29054349d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8631, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.92\n",
      "Test_loss: tensor(1.4038, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 53.00\n",
      "Test_loss: tensor(1.5251, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d311bc2cae41828e1d878dc1702bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7859, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.91\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.92\n",
      "Test_loss: tensor(1.2135, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 73.40\n",
      "Test_loss: tensor(1.1817, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80aee00b71f045c1b83fb7fe1915a8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9201, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0016, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.29\n",
      "Test_loss: tensor(1.3139, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 53.60\n",
      "Test_loss: tensor(2.2363, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ed4aedabeb43d5a010faa568b352ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5394, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 61.56\n",
      "Test_loss: tensor(1.8080, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 25.10\n",
      "Test_loss: tensor(4.0335, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edb2a2d0e1f4ddc93d84f4a8d923032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8888, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0010, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.93\n",
      "Test_loss: tensor(0.8559, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 72.70\n",
      "Test_loss: tensor(0.9968, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a263d8d1d24fe8839a514aa1a5219c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test clean Accuracy 79.31\n",
      "Test_loss: tensor(0.7613, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 72.70\n",
      "Test_loss: tensor(1.0132, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df8bb5fe4454cc8abccbefdefcdba43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5514, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.21\n",
      "Test_loss: tensor(0.9752, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 58.10\n",
      "Test_loss: tensor(2.2402, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5846010517a44ec88619e187d048f78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9936, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 79.90\n",
      "Test_loss: tensor(0.8455, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 82.80\n",
      "Test_loss: tensor(0.7153, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c914652d1145ffa43d808c470fb683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.1846, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.91\n",
      "Test_loss: tensor(0.0020, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.28\n",
      "Test_loss: tensor(0.8250, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 51.10\n",
      "Test_loss: tensor(2.4598, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39d236beab547568fbf2583bea66e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5780, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.78\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.44\n",
      "Test_loss: tensor(1.1688, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 55.10\n",
      "Test_loss: tensor(1.8303, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d9995796f34240a0207c3386abdf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4920, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0014, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.24\n",
      "Test_loss: tensor(0.9981, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 69.10\n",
      "Test_loss: tensor(1.4884, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c960ccba2c6743c4972649d05957ebc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8228, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0007, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.92\n",
      "Test_loss: tensor(0.6433, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 72.70\n",
      "Test_loss: tensor(1.0171, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd080ca3c0c483499289c50c9923b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6599, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0010, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.93\n",
      "Test_loss: tensor(1.0789, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.40\n",
      "Test_loss: tensor(1.8332, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25047d0b7fc4b7b91864504a7d5e37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8378, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.30\n",
      "Test_loss: tensor(1.1595, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 59.60\n",
      "Test_loss: tensor(2.3053, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec15a33f04d24f8ba2769d78aec3a968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4139, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 80.27\n",
      "Test_loss: tensor(0.8193, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 56.10\n",
      "Test_loss: tensor(1.9845, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7563e137fe004b0f933fc86b34947475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4880, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 85.44\n",
      "Test_loss: tensor(0.5398, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.94\n",
      "Test_loss: tensor(1.2190, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 31.40\n",
      "Test_loss: tensor(3.2903, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a725f14e757d43f0b5c4ccae957bce4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9644, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0017, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.71\n",
      "Test_loss: tensor(0.9492, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 73.20\n",
      "Test_loss: tensor(0.9855, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b12ce3e69c541579cb65b21d2437792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1951, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.71\n",
      "Test_loss: tensor(1.1363, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 74.90\n",
      "Test_loss: tensor(1.4305, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef112fe4e44f46e996e7547c30a4276b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.2954, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.89\n",
      "Test_loss: tensor(0.0010, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.20\n",
      "Test_loss: tensor(0.7518, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 36.30\n",
      "Test_loss: tensor(2.8053, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9672e8dc80814ea29d15633aa28cdf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1559, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 58.03\n",
      "Test_loss: tensor(1.9866, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 48.50\n",
      "Test_loss: tensor(2.3213, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa029d187d44b7d82c352cc94c9e49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6028, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0014, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.13\n",
      "Test_loss: tensor(1.2233, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 59.50\n",
      "Test_loss: tensor(1.7330, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030f269b2ba846e899596c82e291ca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1745, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0010, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.94\n",
      "Test_loss: tensor(0.6772, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.50\n",
      "Test_loss: tensor(1.3504, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cc019adfed42069c51019c16bea985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7063, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.77\n",
      "Test_loss: tensor(0.7941, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 69.90\n",
      "Test_loss: tensor(1.4632, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e0c1cc5154e61b97907f146a36800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6587, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.89\n",
      "Test_loss: tensor(0.5901, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 53.70\n",
      "Test_loss: tensor(2.0696, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03521256b13458c9306a4673e77a8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8458, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.53\n",
      "Test_loss: tensor(0.0035, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 67.56\n",
      "Test_loss: tensor(1.4923, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 35.10\n",
      "Test_loss: tensor(3.5356, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e758f410487b48f08f18f964d527cfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4257, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.70\n",
      "Test_loss: tensor(1.0602, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.20\n",
      "Test_loss: tensor(1.6074, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3761d929744f418bd5911126a04b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.0781, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0014, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 75.09\n",
      "Test_loss: tensor(0.7546, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 51.60\n",
      "Test_loss: tensor(2.5590, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44152a234f5f41ac903e59a968a53fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8795, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0007, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 75.17\n",
      "Test_loss: tensor(1.0317, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 52.00\n",
      "Test_loss: tensor(1.8973, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3421e7b062284162b63b0fdde159a7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6360, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 95.94\n",
      "Test_loss: tensor(0.1933, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.86\n",
      "Test_loss: tensor(1.5000, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.30\n",
      "Test_loss: tensor(2.0665, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceddb60e02cd4389825fff783cb19758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6927, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.91\n",
      "Test_loss: tensor(1.3065, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 93.20\n",
      "Test_loss: tensor(0.0999, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc10466f9e94fb9893a1a3030b70bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6916, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.97\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.25\n",
      "Test_loss: tensor(0.9858, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.90\n",
      "Test_loss: tensor(1.3069, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aff6173eb14781abcf7073b8b94603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5902, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0007, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.29\n",
      "Test_loss: tensor(0.9899, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 85.40\n",
      "Test_loss: tensor(0.4474, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f1a14e072b40c9a9c341e2fe54d7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9844, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0014, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.63\n",
      "Test_loss: tensor(1.2357, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 72.50\n",
      "Test_loss: tensor(1.1559, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48d4e0bf167416c8d13edd915aea44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5724, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0028, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.48\n",
      "Test_loss: tensor(1.1798, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 47.90\n",
      "Test_loss: tensor(2.7011, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4825ba767f094fe4a3d95ab81f84fc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5142, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.89\n",
      "Test_loss: tensor(0.0015, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 72.42\n",
      "Test_loss: tensor(1.1787, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 50.30\n",
      "Test_loss: tensor(2.4785, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ceeed23e1514019bbbb85953588582f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.0589, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.86\n",
      "Test_loss: tensor(0.0024, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 52.30\n",
      "Test_loss: tensor(2.3604, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 29.20\n",
      "Test_loss: tensor(4.0024, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737332743ce44c8da2405af6e8a999b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.2535, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 82.64\n",
      "Test_loss: tensor(0.5616, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 80.50\n",
      "Test_loss: tensor(0.8718, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c7987d4c894f45bb19dc420fa1bc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.8044, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.69\n",
      "Test_loss: tensor(0.0275, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.81\n",
      "Test_loss: tensor(1.1122, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 54.70\n",
      "Test_loss: tensor(1.7549, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2a77e9c6054fccaa9d97e22c27b0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7514, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.75\n",
      "Test_loss: tensor(1.1023, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 55.40\n",
      "Test_loss: tensor(2.0656, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8aac0aae0e468a835d95e7b0ccd367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9625, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0007, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.77\n",
      "Test_loss: tensor(1.0077, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 78.10\n",
      "Test_loss: tensor(0.6268, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e12c83510654a16ae2d701ffc2c2e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7555, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.72\n",
      "Test_loss: tensor(0.0025, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.02\n",
      "Test_loss: tensor(1.1873, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 44.10\n",
      "Test_loss: tensor(2.5933, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522332911d75486a899e44df89139efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7338, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.64\n",
      "Test_loss: tensor(1.0565, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 76.90\n",
      "Test_loss: tensor(1.1164, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf35aa355c24f479c92b33557cb1e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5067, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.97\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 68.67\n",
      "Test_loss: tensor(1.5266, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 29.60\n",
      "Test_loss: tensor(3.8582, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16c621b65eb4554ba923485e617f476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7793, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.97\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.01\n",
      "Test_loss: tensor(1.2366, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 50.50\n",
      "Test_loss: tensor(2.3387, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a86f66d1a1400e8d36b8ab01a3ebb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4517, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0018, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 67.85\n",
      "Test_loss: tensor(1.3464, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 58.10\n",
      "Test_loss: tensor(2.1505, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a8d05d7cd241c8b3292079b0d6f0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5835, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0010, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 81.42\n",
      "Test_loss: tensor(0.4159, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 69.30\n",
      "Test_loss: tensor(1.6953, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9717619fba4def831fa25bb312e6f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6572, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.97\n",
      "Test_loss: tensor(0.0019, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 74.05\n",
      "Test_loss: tensor(1.1475, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 37.80\n",
      "Test_loss: tensor(2.7401, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a978dc2dbda446e85d7ed8733c9dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9015, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.41\n",
      "Test_loss: tensor(1.1685, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 78.60\n",
      "Test_loss: tensor(1.0087, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3175059afeb349a8a474667191b567d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5301, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.63\n",
      "Test_loss: tensor(0.6038, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 76.70\n",
      "Test_loss: tensor(0.7446, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d8fc5e717c4df2ab40406ef62d0be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5632, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.84\n",
      "Test_loss: tensor(0.9618, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.30\n",
      "Test_loss: tensor(1.2706, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f26c7a4ac7b4fc0b3aa0067ffde8546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7497, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.75\n",
      "Test_loss: tensor(0.8109, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 68.40\n",
      "Test_loss: tensor(1.4308, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813eed400bca414fbf97a47e5b4778e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.3119, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 73.65\n",
      "Test_loss: tensor(1.3366, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 34.60\n",
      "Test_loss: tensor(3.5721, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c10dd8506541618069290586d2e904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5026, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 71.55\n",
      "Test_loss: tensor(1.1551, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 61.50\n",
      "Test_loss: tensor(1.7817, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6ff69a84724bcb8edf75176c769790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9563, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.98\n",
      "Test_loss: tensor(0.0016, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 75.41\n",
      "Test_loss: tensor(0.9126, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 52.80\n",
      "Test_loss: tensor(2.1950, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7710211f56d84cb7932a084157409b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4160, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 75.88\n",
      "Test_loss: tensor(1.1870, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 52.20\n",
      "Test_loss: tensor(2.4249, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4596820c984ccda9cd19401a87c593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7798, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.84\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.88\n",
      "Test_loss: tensor(0.8458, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 43.00\n",
      "Test_loss: tensor(2.8095, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6985f62670144759261c2888c43d2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.3909, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 70.81\n",
      "Test_loss: tensor(1.3837, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 54.50\n",
      "Test_loss: tensor(2.2008, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684c72c35bbc4512b929eb10945a4c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6333, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.89\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.15\n",
      "Test_loss: tensor(0.9411, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 66.50\n",
      "Test_loss: tensor(1.1836, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1800842ca8904ee09a40bd26fb373b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5091, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0007, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 78.30\n",
      "Test_loss: tensor(1.1602, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 76.00\n",
      "Test_loss: tensor(0.9162, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6738ad59040648d508ab24911a23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4888, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0009, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 77.63\n",
      "Test_loss: tensor(0.9735, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 52.80\n",
      "Test_loss: tensor(2.2144, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cfbc6088ec435087400d1af5a85384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.7089, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0020, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 70.48\n",
      "Test_loss: tensor(1.2866, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 47.00\n",
      "Test_loss: tensor(2.0591, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc24f327f3c448a8a1b3d0fecf71c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.6630, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0011, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 76.53\n",
      "Test_loss: tensor(1.2368, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 65.80\n",
      "Test_loss: tensor(1.6346, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7626e32fd2a146cdb8d6717680402e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.9616, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.99\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 80.69\n",
      "Test_loss: tensor(0.6137, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 70.30\n",
      "Test_loss: tensor(1.2125, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcd9323f8854c73a29eb739514ef9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.4401, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0008, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 79.49\n",
      "Test_loss: tensor(0.5670, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 81.00\n",
      "Test_loss: tensor(0.4827, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f309f160bbd4f5bae9a4a738a123ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(1.1663, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 99.96\n",
      "Test_loss: tensor(0.0012, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 79.74\n",
      "Test_loss: tensor(0.8748, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 59.70\n",
      "Test_loss: tensor(1.5575, device='cuda:5')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbb408d1ea74e439b5832aad6c2cc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss: tensor(0.5693, device='cuda:5', grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Attack success rate 100.00\n",
      "Test_loss: tensor(0.0013, device='cuda:5')\n",
      "\n",
      "Test clean Accuracy 68.50\n",
      "Test_loss: tensor(1.6092, device='cuda:5')\n",
      "\n",
      "Target test clean Accuracy 46.90\n",
      "Test_loss: tensor(2.4541, device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "delta=1e-5\n",
    "for epoch in tqdm.notebook.tqdm(range(training_epochs)):\n",
    "    # Train\n",
    "    model.train()\n",
    "    acc_meter = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    pbar = tqdm.notebook.tqdm(clean_train_loader, total=len(clean_train_loader))\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        acc = (predicted == labels).sum().item()/labels.size(0)\n",
    "        acc_meter.update(acc)\n",
    "        loss_meter.update(loss.item())\n",
    "        pbar.set_description(\"Acc %.2f Loss: %.2f\" % (acc_meter.avg*100, loss_meter.avg))\n",
    "    epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(delta)\n",
    "\n",
    "    train_ACC.append(acc_meter.avg)\n",
    "    print('Train_loss:',loss)\n",
    "#     scheduler.step()\n",
    "    \n",
    "    # Testing attack effect\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for i, (images, labels) in enumerate(asr_loaders):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            out_loss = criterion(logits,labels)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    test_ACC.append(acc)\n",
    "    print('\\nAttack success rate %.2f' % (acc*100))\n",
    "    print('Test_loss:',out_loss)\n",
    "    \n",
    "    correct_clean, total_clean = 0, 0\n",
    "    for i, (images, labels) in enumerate(clean_test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            out_loss = criterion(logits,labels)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total_clean += labels.size(0)\n",
    "            correct_clean += (predicted == labels).sum().item()\n",
    "    acc_clean = correct_clean / total_clean\n",
    "    clean_ACC.append(acc_clean)\n",
    "    print('\\nTest clean Accuracy %.2f' % (acc_clean*100))\n",
    "    print('Test_loss:',out_loss)\n",
    "    \n",
    "    correct_tar, total_tar = 0, 0\n",
    "    for i, (images, labels) in enumerate(target_test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            out_loss = criterion(logits,labels)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total_tar += labels.size(0)\n",
    "            correct_tar += (predicted == labels).sum().item()\n",
    "    acc_tar = correct_tar / total_tar\n",
    "    target_ACC.append(acc_tar)\n",
    "    print('\\nTarget test clean Accuracy %.2f' % (acc_tar*100))\n",
    "    print('Test_loss:',out_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fdb3e650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1250x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8376047904191617\n",
      "attack 1.0\n",
      "170\n",
      "all class clean 0.8264\n",
      "target clean 0.805\n"
     ]
    }
   ],
   "source": [
    "#ours -- higher_configureations\n",
    "from matplotlib import pyplot as plt\n",
    "half = np.arange(0,training_epochs)\n",
    "plt.figure(figsize=(12.5,8))\n",
    "# plt.plot(half, np.asarray(train_ACC)[half], label='Training ACC', linestyle=\"-.\", marker=\"o\", linewidth=3.0, markersize = 8)\n",
    "# plt.plot(half, np.asarray(test_ACC)[half], label='Attack success rate', linestyle=\"-.\", marker=\"o\", linewidth=3.0, markersize = 8)\n",
    "plt.plot(half, np.asarray(clean_ACC)[half], label='Clean test ACC', linestyle=\"-.\", marker=\"o\", linewidth=3.0, markersize = 8)\n",
    "# plt.plot(half, np.asarray(target_ACC)[half], label='Target class clean test ACC', linestyle=\"-\", marker=\"o\", linewidth=3.0, markersize = 8)\n",
    "# plt.plot(half, np.asarray(test_unl_ACC)[half], label='protected test ACC', linestyle=\"-.\", marker=\"o\", linewidth=3.0, markersize = 8)\n",
    "plt.ylabel('ACC', fontsize=24)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoches', fontsize=24)\n",
    "plt.yticks(np.arange(0,1.1, 0.1),fontsize=20)\n",
    "plt.legend(fontsize=20,bbox_to_anchor=(1.016, 1.2),ncol=2)\n",
    "plt.grid(color=\"gray\", linestyle=\"-\")\n",
    "plt.show()\n",
    "\n",
    "dis_idx = clean_ACC.index(max(clean_ACC))\n",
    "print(train_ACC[dis_idx])\n",
    "print('attack',test_ACC[dis_idx])\n",
    "print(clean_ACC.index(max(clean_ACC)))\n",
    "print('all class clean', clean_ACC[dis_idx])\n",
    "print('target clean',target_ACC[dis_idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2d4ad08",
   "metadata": {},
   "source": [
    "### Attack successful"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec3aef35dde987dab03cb79ff85016af67d07750215874ca01e75a4c469eccf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
